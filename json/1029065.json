{
    "title": "使用神经网络生成minecraft皮肤",
    "author": "luzhengwei",
    "replyCount": 5,
    "timestamp": 1587802680,
    "txt_content": " 本帖最后由 luzhengwei 于 2020-5-18 12:57 编辑 \n\n使用神经网络生成皮肤\n\n序言\n\n随着人工智能的发展，越来越多的生活细节可以被其取代，从2012年Alex发布的网络开始，深度学习重新升温，并且在多年后依旧保持活力，成为了机器学习领域的热门话题。\n\n近几年通过神经网络（深度神经网络），在计算机视觉领域取得了巨大的进展，尤其是GAN（生成对抗网络）的提出，为神经网络的应用开辟了一个新的领域（当然，之前也可以通过CNNs来产生图片，但是效果上不够理想）。\n\n尝试\n\n在深度学习的GAN网络中，近几年提出了很多有意思的网络，比如CycleGAN，通过双向生成判定来不断训练产生效果惊人的图片，但是他们都无法指定生成风格。\n\n\n\n如上图，通过输入两幅图像，A和B，神经网络学习图像的内容Content 和 风格Style来进行重新生成，将图像B的风格混合入A的内容中，上图通过语义分析来将语义以隐变量的形式嵌入原图中从而生成指定风格的图篇，但在高清的自然图像上效果并不好，随即产生了Pix2pix，并在高清数据集上获得了不错的成绩。\n\n回到现在的话题，如何通过神经网络生成Minecraft中的皮肤呢，在历来的研究中，从最早的256x256低分辨率的图片再到后来1024x1024的高清图像，每年的Deeplearning都会带来非常不错的新的研究结果，这篇教程，以2018年底至2019年初发表的StyleGAN为基础，配合之后的相关研究StyleGAN-encoder,来生成新的Minecraft皮肤图片。因为神经网络的输入图片往往是固定的，我们仅仅考虑64x64的双层普通皮肤。这篇教程对新手不友好，但由于Python的易用性，推荐作为学习研究使用，对Python稍有了解便可以使用。\n\n数据库：8400+网络爬取图片，和部分站内资源，这里不予公开防止任何版权问题。通过本教程和附带资源产生的皮肤图片，仅仅允许学习使用，新生成的差异较大的图片允许商业用途，具体版权归属见注。\n\n电脑性能要求：有一块独立显卡，性能要求在GTX1060（包括移动端）及以上，（更低的我不知道能不能跑）。\n\npython及相关软件要求：python版本3.6+，tensorflow版本1.10+，cuda7.5+\n\n注：关于GAN网络，或者说人工智能生成产物的归属权问题。现在没有定论，需要根据生成的相似度来评价。对于神经网络的操作者，一般情况下会获得其著作权。如果图片相似度过大，可以提起争议，如果通过本教程生成的所有皮肤发生的任何权利纠纷，仅与操作者相关。本篇教程的部分演示产物，解释权仅归本人所有。其中所有原创图片禁止搬运，禁止商业用途，仅允许学习研究使用。其中使用的所有源码框架均为开源协议，代码部分请参看具体协议内容。\n\n好了，到目前为止，所有思想准备已经完成（估计已经没有人了，hhh），假设你是一个可以使用Python并且机器（电脑配置）还行的玩家，那么我们开始吧。\n\n之前提到这篇教程将会使用Nvidia团队开源的StyleGAN，和其相关成果StyleGAN-encoder。那么从哪里获取呢？这里如果你熟知神经网络那么你可以直接在github上下载相关资源修改部分网络结构，构建数据集并训练。\n如果不是，那么请首先前往我的 github 并切换到minecraft-skins分支中拷贝该项目。\n\nStep1\n\n如果是通过我的github中的minecraft分支进行拷贝，那么我们可以开始进行其他包的导入了，这里我使用的IDE时PyCharm，首先将分支导入IDE中并准备导入相关包，其中可能遇到问题的应该只有opencv的导入，当你使用：\npip install opencv-python复制代码\n后，可能会出现找不到opencv相关函数的错误，此时进入你的python安装目录（如果你使用anaconda，请同样进入到相关环境下修改） 你的目录\\Lib\\site-packages\\cv2  中将 cv2.cp37-win_amd64.pyd 文件复制一份放到 你的目录\\Lib\\site-packages 下并重命名为cv2.pyd。如下图所示：\n\n\n\n当所有库导入完成后，我们得到的目录结构如下图所示：\n\n\n\n其中：\n\ntest_images 为你的目标生成图目录\n\nlatent_representations 为你的隐变量存储目录对应你的所有生成图\n\nresults为你的融合图或者训练备份或者随机生成图的目录\n\ngenerated_images 为你的指定方向生成图或混合图像的目录\n\ncache 为你的StyleGAN网络模型包目录\n\ndata 为反向网络模型目录\n\nmodels 为StyleGAN本身的模型目录\n\n然后，请到mega或天翼云盘或百度网盘（7beh）下载已经预训练过的网络模型:\n\n将finetuned_resnet.h5放入文件夹data中。\n\n将network-snapshot-001640.pkl放入models中。\n\nStep2\n\n使用神经网络随机生成皮肤和融合皮肤。\n\n因为我已经粗粗训练过了一份网络模型，也存储在了相应目录，所以你现在要做的是在项目根目录下，运行：\n\npython generate_figures复制代码\n如果你没有对generate_figures.py进行修改的话，你在生成文件夹下（results）应该会得到如下结果\n\n\n\n上图中前十张为随机生成的图片，figure02-uncurated.png 为组成阵列的多个皮肤图，最后的为随机融合的图片。\n\n\n\n\n\n\n\n关于最后一幅图，我们仅仅从mc的皮肤贴图上可能很难看出区别，这里截取前两行来做解释：\n\n\n\n如上图第一行为风格图片，意味着包含着风格信息，左侧第一列为内容图，是我们的主体。\n\n融合意味着将上面第一行的风格糅合进左侧的内容中，我们稍作分析，以第2行第2列的贴图为例，我们可以看到其中间的身体部分变浅了，第二行第二列的手臂获得了浅色的部分而骷髅的贴图给了被融合图片更多的细节。\n\nStep3\n\n我们现在可以随机生成皮肤了，但是有时候我们更希望生成一幅拥有指定风格的皮肤，比如我现在有一份皮肤（来自于本站资源）：\n\n\n\n我希望产生一张图片和她很像尽量相同，那么，首先将你要趋近生成的图放在test_images下，并在根目录下运行：\n\npython encode_images test_images/ generated_images/ latent_representations/ --model_res 64复制代码\n默认情况下会进行100次迭代并生成所有图像在generate_images目录下，对应生成的贴图如下图：\n\n\n\n我们放大来看：\n\n\n\n可以看到在整体上恢复得还可以但是在很多细节上，比如纹理和眼睛上有不少的模糊和缺失，要改善效果你可以重新训练更大的数据集和更久的周期。也可以在生成时进行更多得迭代。这里可以搜索网上关于StyleGAN和StyleGAN-encoder的文章，具体操作不在本教程内。\n\n同样的我们也可以融合指定的两幅图像：\n\n\n\n上图中最左侧和最右侧为我们的生成图原图，中间5幅图片为融合图片。可以看到非常明显的颜色迁移变化。\n\n\n\n上图为其中一幅融合图片的模型展示。\n\n如何操作：\n\n如果你想融合指定的两幅图，在mix_style.py文件中修改函数\n\nchange_style_figure('mixed-figure', 'mix1', 'mix2', Gs,style_ranges=[range(0, 2), range(2, 4), range(4, 6), range(6, 8), range(8,10)])复制代码\n其中第1个参数代表你要生成的融合图的名字，第二三个参数是你要混合的两幅图的路径，后面的ranges为你要替换的隐变量的位置填入0-10即可，这里如果不理解不要修改。\n\n最后在根目录下运行：\n\npython mix_style.py复制代码\n结尾的话\n\n到目前为止，经过我2天的训练，生成效果并不是很好，只能达到勉强可以用的程度，但是可以看到用神经网络生成皮肤是可行的在这里我也提供测试过程中的生成结果，共10000份生成皮肤，该皮肤集合仅做学习使用，未经我的许可禁止商用，如要使用请私信我，并进行仔细比对防止出现雷同侵权的情况。\n\nhttps://nowandfuture.lanzous.com/ibvvhza\n\n\n\n",
    "replies": [
        {
            "author": "Mars_xiaokai1",
            "timestamp": 1587805320,
            "txt_content": " 看懵了，萌新只能看出使用python写的"
        },
        {
            "author": "387686338",
            "timestamp": 1587808620,
            "txt_content": "66666xxxxx"
        },
        {
            "author": "ItIsEnderman",
            "timestamp": 1587809280,
            "txt_content": "连水印都仿造了，这点希望修复一下"
        },
        {
            "author": "286704984",
            "timestamp": 1589551500,
            "txt_content": "有点懵，看了半天，但是还在努力学QWQ"
        },
        {
            "author": "popooosss",
            "timestamp": 1589716800,
            "txt_content": "除了66666不能说更多了"
        }
    ]
}