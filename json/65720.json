{
    "title": "<CaKE>辩论赛：“它”，有意识吗？来把大家的逻辑思维带上来～让红石再也不难～",
    "author": "garytang",
    "replyCount": 15,
    "timestamp": 1353447660,
    "txt_content": " 本帖最后由 garytang 于 2012-11-20 16:42 编辑 \n\n\n--------------------------------------------------------------------------------------------------------------------------------------------------\n首先感谢Forever_小树，是他的建议让我想到了这个活动～\n\n好，步入正题～ 本次的题目是：\n“它”，有意识吗？\n--------------------------------------------------------------------------------------------------------------------------------------------------\n\n在这之前，先请大家看一下意识的定义：\n意识是什么？\n意识是具体事物的组成部分，是人脑把世界万物分成生物和非生物两大类后，从这两大类具体事物中思维抽象出来的绝对抽象事物或元本体，是具体事物的存在、运动和行为表现出来的普遍性规定和本质，是每个具体事物普遍具有的自主、自新、自律的主体性质和能力。\n来自：意识_百度百科，http://baike.baidu.com/view/51715.htm\n\n\n总结一下，意识就是一种物体的“自主” “自新” “自律”的能力\n--------------------------------------------------------------------------------------------------------------------------------------------------\n好了，现在大家都因该对意识有一点了解了。好，我们先来看一下下面几个例子：\n\n首先，石头有意识吗？\n答案：没有，这个是无可争论的，因为它不会对外界的环境的变化作出变化。所以，石头出局～\n\n接下来，傀儡有意识吗？\n答案：没有，看上去它会因为操作傀儡的线运动而运动（对外界作出了反映）但是傀儡不是自己“规定”自己运动，只能是说“被控制”，傀儡也出局～\n\n再来，电饭煲有意识吗？\n答案：这个就有点难度了，因为电饭煲会根据环境的变化（电饭煲内的温度）作出反映，并且会在环境发生变化（温度过高或者温度过低）的时候作出反映（停止或者开始加热），看上去好像有“自主”的能力。但是，如果一个零件坏掉了呢？那它就玩完了，因为它不会自我纠错并调整，也就是缺少“自新”的能力，所以，电饭煲一样出局～\n--------------------------------------------------------------------------------------------------------------------------------------------------\n现在，就轮到由在座各位辩论的环节了，这次的辩题是：\n＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n＝＝计算机程序有意识吗？＝＝\n＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n\n也许有些人已经有答案了，不过且慢～我有一些值得探讨的观点：\n\n\n首先，计算机程序能对外界作出反映（用户的输入，数据的传输等等）并能自行进行处理，相当于有了“自主”的能力\n\n\n再来，如今计算机，早已能够进行复杂的逻辑计算，并且能在适当的情况下作出适当的反映，比如java语言中的try－catch－finally就是一个很好的例子，这段话能够发现错误并将它纠正。等于程序有了“自新”的能力。\n\n\n最后，程序能在适当的环境下面控制自己，比如大部分的操作系统都能自动分配内存，让系统运行的跟顺畅，等于有了“自律”的能力。\n\n\n等等，这样子的话，程序不就有意识了吗？\n--------------------------------------------------------------------------------------------------------------------------------------------------\n我还没说完，虽然程序好像符合了拥有意识的所有定义，但是一个程序是否能“自主”“自新”“自律”是取决于程序的复杂成度来定的，越复杂的越具有逻辑思考的能力。\n\n\n哎...这样子的话，不久是否定了程序有意识了吗？\n--------------------------------------------------------------------------------------------------------------------------------------------------\n咳咳，再听我说一句：“如果（我说的是如果）一个程序能够达到无限的复杂（无限无限无限无限无限无限的复杂）复杂到包含了世界上所有的可能性，并各自有一套反映，处理的方法”，这么一来.....计算机程序到底有没有意识呢？\n\n\n--------------------------------------------------------------------------------------------------------------------------------------------------\n\n现在，辩论正式开始！\n\n\n\n",
    "replies": [
        {
            "author": "geludan",
            "timestamp": 1353448200,
            "txt_content": "首先我们提到的一直都是AI，也就是人工智能，超出人工智能我不予讨论\n那么简单了，既然是人工智能，也就是一举一动，都是经过人类的设置（不一定每一步，但是总体反应和程序）\n而一个意识，需要有自主观念，自我判断，如果这个物体的一举一动虽然很像人，或者和人一模一样，但是全部都是他人设定好的，那这个就不能称之为一个意识\n\n如果有意见可以去看一下philosophical zombie这个观念，还不明白就去看Vsauce的视频"
        },
        {
            "author": "253769436",
            "timestamp": 1353449340,
            "txt_content": "这投票方式怎么弄得？"
        },
        {
            "author": "Hao",
            "timestamp": 1353449340,
            "txt_content": "我只是路过打酱油的- -AI有没有意识我不知道- -但是不知道为什么，如果不是我自己的电脑不是我用的话其他人用都会非常卡= =+（汗）"
        },
        {
            "author": "zzx908",
            "timestamp": 1353449760,
            "txt_content": "计算机特么有意识……汗……"
        },
        {
            "author": "csvscs96",
            "timestamp": 1353453420,
            "txt_content": "@终结者@加州州长,过个10来年在问这个话题吧"
        },
        {
            "author": "yeyaowei",
            "timestamp": 1353469560,
            "txt_content": "没有意识吧，我认为能自己演化出某些东西的就有意识，弄的再复杂也是人输入进去的啊，我自己的想法。。O(∩_∩)O~"
        },
        {
            "author": "猫小沫",
            "timestamp": 1353492960,
            "txt_content": "无意识，如果有意识人类的末日就到了。虽说意识不等于思维\\思想，但是只有能自主思考的物体才从根本意义上是有思维的。"
        },
        {
            "author": "紫枫",
            "timestamp": 1353500040,
            "txt_content": "首先戳小沫，有空泡论坛就没有时间做地图XD\n——————————————————————以上是题外话\n首先，举一个例子：光圈科学（好吧，它并不存在于真实世界）\n那个AI：GlaDOS\n它（她？）就是一个老总过于相信他的助手（小秘？老婆XD）造成的结果\n他的野心十分大，在连八元钱的实验器材都买不起的时候硬要买了八万元钱的实验器材。\n他对小秘也是非常的信任。\n他说过：“如果音乐可以刻进光碟，那么人的思维也可以。我要让我的光圈工程师们CAROLINE的思维也刻进光碟中。我要她在我死后来接管这整个设施！”\n后来，光圈的工程师们做到了，但凯文总裁却没有看到这个日子。\n光圈的工程师们开发出的AI十分不稳定，居然让她有了自主意识，在开机的时候她居然有了自主意识！\n当然，工程师们在第一时间拉掉了电闸，才防止了悲剧的发生。\n工程师们又开发出了很多的核心球，来控制她（它？）的思维，但在“光圈科学首届年度展览”的前一天，最主要的核心还没有完成。\n但是那一天，他们还是启动了那个AI。\n悲剧发生了，\nAI在万亿分之一毫秒内拥有了自主意识，并用“我需要神经毒气来做“薛定谔的猫（小沫）”这个实验”这个理由，得到了控制神经毒气的权利。\n然后，她（它？！）立即控制了所有她可以掌握的权利\n并释放神经毒气杀死了这里所有的能杀死的人\n但有一个人在最后一刻把未完成的那个核心给她安装上了，遏制住了她的思维\n但是他（她？）却因伤势过重而死在了AI的面前，从此这个设施便空无一人了（清醒的人，冷冻的实验对象不算）\n后来就发生了雪儿的故事，在她试图谋害雪儿的时候，雪儿成功逃脱了\n她很惊讶：我我我我我……我们很高兴你通过了测试，虽然我们假装要杀死你（诸如此类安慰的话，想告诉雪儿这只是实验的一部分）\n变得不像一个机器人，而是有感情的人\n但是，雪儿终究是她的女儿（当然只是我们玩家的猜测，并且游戏里已经给出了强烈的暗示）\n她也不任性杀死她，她相信雪儿可以逃出去\n雪儿成功了，她从地下1000米回到了地面，但还是被机器人给拖回了冷冻仓\n后来他被一个核心叫醒了，她走过了光圈实验室背后的维护区域和百年后依然运行完好的光圈工厂\n那些核心，都有思维，会跟她交谈（虽然完好的不多了）\n那个AI和广播也会和她开玩笑（黑色玩笑，比如拨了个电话，电话里提示：“你的亲生父母不爱你，请挂断“）\n后来，一开始叫她醒的核心叛变了，把AI装进了小孩子玩土豆电池里\n并把AI和雪儿一起扔进了地下7000米左右的老光圈，虽然过了几个世纪，但那里依然运行完整\n后来她和AI一起破解难关，回到了地下1000米处的光圈\n并让AI重新掌控了这里，因为那个核心根本不爱惜这个设施，把为整个设施提供电力的核反应炉即将爆炸的警报都给关掉了\n后来，AI不仅送雪儿回了地面，还说：”地下的那番历程让我找回了CAROLINE的人格（系统广播：CAROLINE，已删除。当然那是她故意让广播说的）“\n还让机枪塔们为她演唱了意大利歌剧！\n可见，这个人工智能，它仅以1.1伏特的极低功率运行，拥有和人一样的思维，零件缺失可以自行更换（虽然除了雪儿拆掉核心让她过载爆炸之外没有坏过），爆炸后还可以自行重组、更换系统核心等等操作，还可以自主做出拥有半自主思维的机器人来！\n谁说AI没有思维？"
        },
        {
            "author": "紫枫",
            "timestamp": 1353500100,
            "txt_content": " 本帖最后由 紫枫 于 2012-11-21 20:16 编辑 \n\n首先戳小沫，有空泡论坛就没有时间做地图XD\n——————————————————————以上是题外话\n首先，举一个例子：光圈科学（好吧，它并不存在于真实世界）\n那个AI：GlaDOS\n它（她？）就是一个老总过于相信他的助手（小秘？老婆XD）造成的结果\n他的野心十分大，在连八元钱的实验器材都买不起的时候硬要买了八万元钱的实验器材。\n他对小秘也是非常的信任。\n他说过：“如果音乐可以刻进光碟，那么人的思维也可以。我要让我的光圈工程师们CAROLINE的思维也刻进光碟中。我要她在我死后来接管这整个设施！”\n后来，光圈的工程师们做到了，但凯文总裁却没有看到这个日子。\n光圈的工程师们开发出的AI十分不稳定，居然让她有了自主意识，在开机的时候她居然有了自主意识！\n当然，工程师们在第一时间拉掉了电闸，才防止了悲剧的发生。\n工程师们又开发出了很多的核心球，来控制她（它？）的思维，但在“光圈科学首届年度展览”的前一天，最主要的核心还没有完成。\n但是那一天，他们还是启动了那个AI。\n悲剧发生了，\nAI在万亿分之一毫秒内拥有了自主意识，并用“我需要神经毒气来做“薛定谔的猫（小沫）”这个实验”这个理由，得到了控制神经毒气的权利。\n然后，她（它？！）立即控制了所有她可以掌握的权利\n并释放神经毒气杀死了这里所有的能杀死的人\n但有一个人在最后一刻把未完成的那个核心给她安装上了，遏制住了她的思维\n但是他（她？）却因伤势过重而死在了AI的面前，从此这个设施便空无一人了（清醒的人，冷冻的实验对象不算）\n后来就发生了雪儿的故事，在她试图谋害雪儿的时候，雪儿成功逃脱了\n她很惊讶：我我我我我……我们很高兴你通过了测试，虽然我们假装要杀死你（诸如此类安慰的话，想告诉雪儿这只是实验的一部分）\n变得不像一个机器人，而是有感情的人\n但是，雪儿终究是她的女儿（当然只是我们玩家的猜测，并且游戏里已经给出了强烈的暗示）\n她也不任性杀死她，她相信雪儿可以逃出去\n雪儿成功了，她从地下1000米回到了地面，但还是被机器人给拖回了冷冻仓\n后来他被一个核心叫醒了，她走过了光圈实验室背后的维护区域和百年后依然运行完好的光圈工厂\n那些核心，都有思维，会跟她交谈（虽然完好的不多了）\n那个AI和广播也会和她开玩笑（黑色玩笑，比如拨了个电话，电话里提示：“你的亲生父母不爱你，请挂断“）\n后来，一开始叫她醒的核心叛变了，把AI装进了小孩子玩土豆电池里\n并把AI和雪儿一起扔进了地下7000米左右的老光圈，虽然过了几个世纪，但那里依然运行完整\n后来她和AI一起破解难关，回到了地下1000米处的光圈\n并让AI重新掌控了这里，因为那个核心根本不爱惜这个设施，把为整个设施提供电力的核反应炉即将爆炸的警报都给关掉了\n后来，AI不仅送雪儿回了地面，还说：”地下的那番历程让我找回了CAROLINE的人格（系统广播：CAROLINE，已删除。当然那是她故意让广播说的）“\n还让机枪塔们为她演唱了意大利歌剧！\n可见，这个人工智能，它仅以1.1伏特的极低功率运行，拥有和人一样的思维，零件缺失可以自行更换（虽然除了雪儿拆掉核心让她过载爆炸之外没有坏过），爆炸后还可以自行重组、更换系统核心等等操作，还可以自主做出拥有半自主思维的机器人来！\n谁说AI没有思维？\n————————————————————手残卡了点了两次，请原谅\n"
        },
        {
            "author": "xyx0826",
            "timestamp": 1353502500,
            "txt_content": "如果一个程序通过了图灵测试，那才是真的\"有意识\"。"
        },
        {
            "author": "橘子VI",
            "timestamp": 1353505260,
            "txt_content": "其实这里讨论的就是攻壳机动队里想表达的吧，当程序过于细致和拟人，当人类太过于借助机械的时候，程序有没有思维就是个很模糊的问题了。"
        },
        {
            "author": "ufo999wc",
            "timestamp": 1353586020,
            "txt_content": "如果人类给了机器一个指令使它可以不断的自我完善，最后也不就可以拥有意识了呗。\n我只是扯淡，别介意"
        },
        {
            "author": "282725559",
            "timestamp": 1353586980,
            "txt_content": "电脑也会坏吧"
        },
        {
            "author": "Sky、果冻",
            "timestamp": 1353587160,
            "txt_content": "话说这和Cake小组有半毛钱关系吗。。。"
        },
        {
            "author": "Danny仔",
            "timestamp": 1353587580,
            "txt_content": "就算多麼複雜，都只是人類的產品，什麼意識都是假象吧，例如人類怎麼改，它就怎麼做，所以我個人認為是沒意識吧~"
        }
    ]
}