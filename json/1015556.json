{
    "title": "python3 读取并修改文件",
    "author": "(=°ω°)丿",
    "replyCount": 5,
    "timestamp": 1586613000,
    "txt_content": "python3 是否有方法可以读取并修改例如原版末地船的 nbt 或者 command storage 等文件？",
    "replies": [
        {
            "author": "阴阳师元素祭祀",
            "timestamp": 1586613000,
            "txt_content": " 本帖最后由 阴阳师元素祭祀 于 2020-4-11 22:35 编辑 \n(=°ω°)丿 发表于 2020-4-11 22:24\n那你就帮我把 https://pca006132.neocities.org/tutorials/nbt/format.html 里的 python nbt 库下载下来 ...\n因为不会下载\n所以..请原谅我这样发文件\nhttps://github.com/twoolie/NBT\n\n是重要的协议：\n Copyright (c) 2010-2013 Thomas Woolford and contributors\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in\n all copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n THE SOFTWARE.\nnbt/__init__.py\n\n\n__all__ = [\"nbt\", \"world\", \"region\", \"chunk\"]\nfrom . import *\n\n# Documentation only automatically includes functions specified in __all__.\n# If you add more functions, please manually include them in doc/index.rst.\n\nVERSION = (1, 5, 0)\n\"\"\"NBT version as tuple. Note that the major and minor revision number are \nalways present, but the patch identifier (the 3rd number) is only used in 1.4.\"\"\"\n\ndef _get_version():\n    \"\"\"Return the NBT version as string.\"\"\"\n    return \".\".join([str(v) for v in VERSION])\n复制代码\n\n\nnbt/chunk.py\n\n\n\"\"\"\nHandles a single chunk of data (16x16x128 blocks) from a Minecraft save.\nFor more information about the chunck format:\nhttps://minecraft.gamepedia.com/Chunk_format\n\"\"\"\n\nfrom io import BytesIO\nfrom struct import pack\nimport array\nimport nbt\n\n\n# Legacy numeric block identifiers\n# mapped to alpha identifiers in best effort\n# See https://minecraft.gamepedia.com/Java_Edition_data_values/Pre-flattening\n# TODO: move this map into a separate file\n\nblock_ids = {\n      0: 'air',\n      1: 'stone',\n      2: 'grass_block',\n      3: 'dirt',\n      4: 'cobblestone',\n      5: 'oak_planks',\n      6: 'sapling',\n      7: 'bedrock',\n      8: 'flowing_water',\n      9: 'water',\n     10: 'flowing_lava',\n     11: 'lava',\n     12: 'sand',\n     13: 'gravel',\n     14: 'gold_ore',\n     15: 'iron_ore',\n     16: 'coal_ore',\n     17: 'oak_log',\n     18: 'oak_leaves',\n     19: 'sponge',\n     20: 'glass',\n     21: 'lapis_ore',\n     24: 'sandstone',\n     30: 'cobweb',\n     31: 'grass',\n     32: 'dead_bush',\n     35: 'white_wool',\n     37: 'dandelion',\n     38: 'poppy',\n     39: 'brown_mushroom',\n     40: 'red_mushroom',\n     43: 'stone_slab',\n     44: 'stone_slab',\n     47: 'bookshelf',\n     48: 'mossy_cobblestone',\n     49: 'obsidian',\n     50: 'torch',\n     51: 'fire',\n     52: 'spawner',\n     53: 'oak_stairs',\n     54: 'chest',\n     56: 'diamond_ore',\n     58: 'crafting_table',\n     59: 'wheat',\n     60: 'farmland',\n     61: 'furnace',\n     62: 'furnace',\n     63: 'sign',  # will change to oak_sign in 1.14\n     64: 'oak_door',\n     65: 'ladder',\n     66: 'rail',\n     67: 'cobblestone_stairs',\n     72: 'oak_pressure_plate',\n     73: 'redstone_ore',\n     74: 'redstone_ore',\n     78: 'snow',\n     79: 'ice',\n     81: 'cactus',\n     82: 'clay',\n     83: 'sugar_cane',\n     85: 'oak_fence',\n     86: 'pumpkin',\n     91: 'lit_pumpkin',\n    101: 'iron_bars',\n    102: 'glass_pane',\n    }\n\n\ndef block_id_to_name(bid):\n    try:\n        name = block_ids[bid]\n    except KeyError:\n        name = 'unknown_%d' % (bid,)\n        print(\"warning: unknown block id %i\" % bid)\n        print(\"hint: add that block to the 'block_ids' map\")\n    return name\n\n\n# Generic Chunk\n\nclass Chunk(object):\n    \"\"\"Class for representing a single chunk.\"\"\"\n    def __init__(self, nbt):\n        self.chunk_data = nbt['Level']\n        self.coords = self.chunk_data['xPos'],self.chunk_data['zPos']\n\n    def get_coords(self):\n        \"\"\"Return the coordinates of this chunk.\"\"\"\n        return (self.coords[0].value,self.coords[1].value)\n\n    def __repr__(self):\n        \"\"\"Return a representation of this Chunk.\"\"\"\n        return \"Chunk(\"+str(self.coords[0])+\",\"+str(self.coords[1])+\")\"\n\n\n# Chunk in Region old format\n\nclass McRegionChunk(Chunk):\n\n    def __init__(self, nbt):\n        Chunk.__init__(self, nbt)\n        self.blocks = BlockArray(self.chunk_data['Blocks'].value, self.chunk_data['Data'].value)\n\n    def get_max_height(self):\n        return 127\n\n    def get_block(self, x, y, z):\n        name = block_id_to_name(self.blocks.get_block(x, y, z))\n        return name\n\n    def iter_block(self):\n        for y in range(0, 128):\n            for z in range(0, 16):\n                for x in range(0, 16):\n                    yield self.get_block(x, y, z)\n\n\n# Section in Anvil new format\n\nclass AnvilSection(object):\n\n    def __init__(self, nbt, version):\n        self.names = []\n        self.indexes = []\n\n        # Is the section flattened ?\n        # See https://minecraft.gamepedia.com/1.13/Flattening\n\n        if version == 0 or version == 1343:  # 1343 = MC 1.12.2\n            self._init_array(nbt)\n        elif version == 1631:  # MC 1.13\n            self._init_index(nbt)\n        else:\n            raise NotImplementedError()\n\n        # Section contains 4096 blocks whatever data version\n\n        assert len(self.indexes) == 4096\n\n\n    # Decode legacy section\n    # Contains an array of block numeric identifiers\n\n    def _init_array(self, nbt):\n        bids = []\n        for bid in nbt['Blocks'].value:\n            try:\n                i = bids.index(bid)\n            except ValueError:\n                bids.append(bid)\n                i = len(bids) - 1\n            self.indexes.append(i)\n\n        for bid in bids:\n            bname = block_id_to_name(bid)\n            self.names.append(bname)\n\n\n    # Decode modern section\n    # Contains palette of block names and indexes\n\n    def _init_index(self, nbt):\n\n        for p in nbt['Palette']:\n            name = p['Name'].value\n            if name.startswith('minecraft:'):\n                name = name[10:]\n            self.names.append(name)\n\n        states = nbt['BlockStates'].value\n\n        # Block states are packed into an array of longs\n        # with variable number of bits per block (min: 4)\n\n        nb = (len(self.names) - 1).bit_length()\n        if nb < 4: nb = 4\n        assert nb == len(states) * 8 * 8 / 4096\n        m = pow(2, nb) - 1\n\n        j = 0\n        bl = 64\n        ll = states[0]\n\n        for i in range(0,4096):\n            if bl == 0:\n                j = j + 1\n                ll = states[j]\n                bl = 64\n\n            if nb <= bl:\n                self.indexes.append(ll & m)\n                ll = ll >> nb\n                bl = bl - nb\n            else:\n                j = j + 1\n                lh = states[j]\n                bh = nb - bl\n\n                lh = (lh & (pow(2, bh) - 1)) << bl\n                ll = (ll & (pow(2, bl) - 1))\n                self.indexes.append(lh | ll)\n\n                ll = states[j]\n                ll = ll >> bh\n                bl = 64 - bh\n\n\n    def get_block(self, x, y, z):\n        # Blocks are stored in YZX order\n        i = y * 256 + z * 16 + x\n        p = self.indexes[i]\n        return self.names[p]\n\n\n    def iter_block(self):\n        for i in range(0, 4096):\n            p = self.indexes[i]\n            yield self.names[p]\n\n\n# Chunck in Anvil new format\n\nclass AnvilChunk(Chunk):\n\n    def __init__(self, nbt):\n        Chunk.__init__(self, nbt)\n\n        # Started to work on this class with MC version 1.13.2\n        # so with the chunk data version 1631\n        # Backported to first Anvil version (= 0) from examples\n        # Could work with other versions, but has to be tested first\n\n        try:\n            version = nbt['DataVersion'].value\n            if version != 1343 and version != 1631:\n                raise NotImplementedError('DataVersion %d not implemented' % (version,))\n        except KeyError:\n            version = 0\n\n        # Load all sections\n\n        self.sections = {}\n        if 'Sections' in self.chunk_data:\n            for s in self.chunk_data['Sections']:\n                self.sections[s['Y'].value] = AnvilSection(s, version)\n\n\n    def get_section(self, y):\n        \"\"\"Get a section from Y index.\"\"\"\n        if y in self.sections:\n            return self.sections[y]\n\n        return None\n\n\n    def get_max_height(self):\n        ymax = 0\n        for y in self.sections.keys():\n            if y > ymax: ymax = y\n        return ymax * 16 + 15\n\n\n    def get_block(self, x, y, z):\n        \"\"\"Get a block from relative x,y,z.\"\"\"\n        sy,by = divmod(y, 16)\n        section = self.get_section(sy)\n        if section == None:\n            return None\n\n        return section.get_block(x, by, z)\n\n\n    def iter_block(self):\n        for s in self.sections.values():\n            for b in s.iter_block():\n                yield b\n\n\nclass BlockArray(object):\n    \"\"\"Convenience class for dealing with a Block/data byte array.\"\"\"\n    def __init__(self, blocksBytes=None, dataBytes=None):\n        \"\"\"Create a new BlockArray, defaulting to no block or data bytes.\"\"\"\n        if isinstance(blocksBytes, (bytearray, array.array)):\n            self.blocksList = list(blocksBytes)\n        else:\n            self.blocksList = [0]*32768 # Create an empty block list (32768 entries of zero (air))\n\n        if isinstance(dataBytes, (bytearray, array.array)):\n            self.dataList = list(dataBytes)\n        else:\n            self.dataList = [0]*16384 # Create an empty data list (32768 4-bit entries of zero make 16384 byte entries)\n\n    def get_blocks_struct(self):\n        \"\"\"Return a dictionary with block ids keyed to (x, y, z).\"\"\"\n        cur_x = 0\n        cur_y = 0\n        cur_z = 0\n        blocks = {}\n        for block_id in self.blocksList:\n            blocks[(cur_x,cur_y,cur_z)] = block_id\n            cur_y += 1\n            if (cur_y > 127):\n                cur_y = 0\n                cur_z += 1\n                if (cur_z > 15):\n                    cur_z = 0\n                    cur_x += 1\n        return blocks\n\n    # Give blockList back as a byte array\n    def get_blocks_byte_array(self, buffer=False):\n        \"\"\"Return a list of all blocks in this chunk.\"\"\"\n        if buffer:\n            length = len(self.blocksList)\n            return BytesIO(pack(\">i\", length)+self.get_blocks_byte_array())\n        else:\n            return array.array('B', self.blocksList).tostring()\n\n    def get_data_byte_array(self, buffer=False):\n        \"\"\"Return a list of data for all blocks in this chunk.\"\"\"\n        if buffer:\n            length = len(self.dataList)\n            return BytesIO(pack(\">i\", length)+self.get_data_byte_array())\n        else:\n            return array.array('B', self.dataList).tostring()\n\n    def generate_heightmap(self, buffer=False, as_array=False):\n        \"\"\"Return a heightmap, representing the highest solid blocks in this chunk.\"\"\"\n        non_solids = [0, 8, 9, 10, 11, 38, 37, 32, 31]\n        if buffer:\n            return BytesIO(pack(\">i\", 256)+self.generate_heightmap()) # Length + Heightmap, ready for insertion into Chunk NBT\n        else:\n            bytes = []\n            for z in range(16):\n                for x in range(16):\n                    for y in range(127, -1, -1):\n                        offset = y + z*128 + x*128*16\n                        if (self.blocksList[offset] not in non_solids or y == 0):\n                            bytes.append(y+1)\n                            break\n            if (as_array):\n                return bytes\n            else:\n                return array.array('B', bytes).tostring()\n\n    def set_blocks(self, list=None, dict=None, fill_air=False):\n        \"\"\"\n        Sets all blocks in this chunk, using either a list or dictionary.  \n        Blocks not explicitly set can be filled to air by setting fill_air to True.\n        \"\"\"\n        if list:\n            # Inputting a list like self.blocksList\n            self.blocksList = list\n        elif dict:\n            # Inputting a dictionary like result of self.get_blocks_struct()\n            list = []\n            for x in range(16):\n                for z in range(16):\n                    for y in range(128):\n                        coord = x,y,z\n                        offset = y + z*128 + x*128*16\n                        if (coord in dict):\n                            list.append(dict[coord])\n                        else:\n                            if (self.blocksList[offset] and not fill_air):\n                                list.append(self.blocksList[offset])\n                            else:\n                                list.append(0) # Air\n            self.blocksList = list\n        else:\n            # None of the above...\n            return False\n        return True\n\n    def set_block(self, x,y,z, id, data=0):\n        \"\"\"Sets the block a x, y, z to the specified id, and optionally data.\"\"\"\n        offset = y + z*128 + x*128*16\n        self.blocksList[offset] = id\n        if (offset % 2 == 1):\n            # offset is odd\n            index = (offset-1)//2\n            b = self.dataList[index]\n            self.dataList[index] = (b & 240) + (data & 15) # modify lower bits, leaving higher bits in place\n        else:\n            # offset is even\n            index = offset//2\n            b = self.dataList[index]\n            self.dataList[index] = (b & 15) + (data << 4 & 240) # modify ligher bits, leaving lower bits in place\n\n    # Get a given X,Y,Z or a tuple of three coordinates\n    def get_block(self, x,y,z, coord=False):\n        \"\"\"Return the id of the block at x, y, z.\"\"\"\n        \"\"\"\n        Laid out like:\n        (0,0,0), (0,1,0), (0,2,0) ... (0,127,0), (0,0,1), (0,1,1), (0,2,1) ... (0,127,1), (0,0,2) ... (0,127,15), (1,0,0), (1,1,0) ... (15,127,15)\n        \n        ::\n        \n          blocks = []\n          for x in range(15):\n            for z in range(15):\n              for y in range(127):\n                blocks.append(Block(x,y,z))\n        \"\"\"\n\n        offset = y + z*128 + x*128*16 if (coord == False) else coord[1] + coord[2]*128 + coord[0]*128*16\n        return self.blocksList[offset]\n复制代码\n\n\nnbt/nbt.py\n\n\n\"\"\"\nHandle the NBT (Named Binary Tag) data format\nFor more information about the NBT format:\nhttps://minecraft.gamepedia.com/NBT_format\n\"\"\"\n\nfrom struct import Struct, error as StructError\nfrom gzip import GzipFile\nfrom collections import MutableMapping, MutableSequence, Sequence\nimport sys\n\n_PY3 = sys.version_info >= (3,)\nif _PY3:\n    unicode = str\n    basestring = str\nelse:\n    range = xrange\n\nTAG_END = 0\nTAG_BYTE = 1\nTAG_SHORT = 2\nTAG_INT = 3\nTAG_LONG = 4\nTAG_FLOAT = 5\nTAG_DOUBLE = 6\nTAG_BYTE_ARRAY = 7\nTAG_STRING = 8\nTAG_LIST = 9\nTAG_COMPOUND = 10\nTAG_INT_ARRAY = 11\nTAG_LONG_ARRAY = 12\n\n\nclass MalformedFileError(Exception):\n    \"\"\"Exception raised on parse error.\"\"\"\n    pass\n\n\nclass TAG(object):\n    \"\"\"TAG, a variable with an intrinsic name.\"\"\"\n    id = None\n\n    def __init__(self, value=None, name=None):\n        self.name = name\n        self.value = value\n\n    # Parsers and Generators\n    def _parse_buffer(self, buffer):\n        raise NotImplementedError(self.__class__.__name__)\n\n    def _render_buffer(self, buffer):\n        raise NotImplementedError(self.__class__.__name__)\n\n    # Printing and Formatting of tree\n    def tag_info(self):\n        \"\"\"Return Unicode string with class, name and unnested value.\"\"\"\n        return self.__class__.__name__ + (\n            '(%r)' % self.name if self.name\n            else \"\") + \": \" + self.valuestr()\n\n    def valuestr(self):\n        \"\"\"Return Unicode string of unnested value. For iterators, this\n        returns a summary.\"\"\"\n        return unicode(self.value)\n\n    def pretty_tree(self, indent=0):\n        \"\"\"Return formated Unicode string of self, where iterable items are\n        recursively listed in detail.\"\"\"\n        return (\"\\t\" * indent) + self.tag_info()\n\n    # Python 2 compatibility; Python 3 uses __str__ instead.\n    def __unicode__(self):\n        \"\"\"Return a unicode string with the result in human readable format.\n        Unlike valuestr(), the result is recursive for iterators till at least\n        one level deep.\"\"\"\n        return unicode(self.value)\n\n    def __str__(self):\n        \"\"\"Return a string (ascii formated for Python 2, unicode for Python 3)\n        with the result in human readable format. Unlike valuestr(), the result\n         is recursive for iterators till at least one level deep.\"\"\"\n        return str(self.value)\n\n    # Unlike regular iterators, __repr__() is not recursive.\n    # Use pretty_tree for recursive results.\n    # iterators should use __repr__ or tag_info for each item, like\n    #  regular iterators\n    def __repr__(self):\n        \"\"\"Return a string (ascii formated for Python 2, unicode for Python 3)\n        describing the class, name and id for debugging purposes.\"\"\"\n        return \"<%s(%r) at 0x%x>\" % (\n            self.__class__.__name__, self.name, id(self))\n\n\nclass _TAG_Numeric(TAG):\n    \"\"\"_TAG_Numeric, comparable to int with an intrinsic name\"\"\"\n\n    def __init__(self, value=None, name=None, buffer=None):\n        super(_TAG_Numeric, self).__init__(value, name)\n        if buffer:\n            self._parse_buffer(buffer)\n\n    # Parsers and Generators\n    def _parse_buffer(self, buffer):\n        # Note: buffer.read() may raise an IOError, for example if buffer is a\n        # corrupt gzip.GzipFile\n        self.value = self.fmt.unpack(buffer.read(self.fmt.size))[0]\n\n    def _render_buffer(self, buffer):\n        buffer.write(self.fmt.pack(self.value))\n\n\nclass _TAG_End(TAG):\n    id = TAG_END\n    fmt = Struct(\">b\")\n\n    def _parse_buffer(self, buffer):\n        # Note: buffer.read() may raise an IOError, for example if buffer is a\n        # corrupt gzip.GzipFile\n        value = self.fmt.unpack(buffer.read(1))[0]\n        if value != 0:\n            raise ValueError(\n                \"A Tag End must be rendered as '0', not as '%d'.\" % value)\n\n    def _render_buffer(self, buffer):\n        buffer.write(b'\\x00')\n\n\n# == Value Tags ==#\nclass TAG_Byte(_TAG_Numeric):\n    \"\"\"Represent a single tag storing 1 byte.\"\"\"\n    id = TAG_BYTE\n    fmt = Struct(\">b\")\n\n\nclass TAG_Short(_TAG_Numeric):\n    \"\"\"Represent a single tag storing 1 short.\"\"\"\n    id = TAG_SHORT\n    fmt = Struct(\">h\")\n\n\nclass TAG_Int(_TAG_Numeric):\n    \"\"\"Represent a single tag storing 1 int.\"\"\"\n    id = TAG_INT\n    fmt = Struct(\">i\")\n    \"\"\"Struct(\">i\"), 32-bits integer, big-endian\"\"\"\n\n\nclass TAG_Long(_TAG_Numeric):\n    \"\"\"Represent a single tag storing 1 long.\"\"\"\n    id = TAG_LONG\n    fmt = Struct(\">q\")\n\n\nclass TAG_Float(_TAG_Numeric):\n    \"\"\"Represent a single tag storing 1 IEEE-754 floating point number.\"\"\"\n    id = TAG_FLOAT\n    fmt = Struct(\">f\")\n\n\nclass TAG_Double(_TAG_Numeric):\n    \"\"\"Represent a single tag storing 1 IEEE-754 double precision floating\n    point number.\"\"\"\n    id = TAG_DOUBLE\n    fmt = Struct(\">d\")\n\n\nclass TAG_Byte_Array(TAG, MutableSequence):\n    \"\"\"\n    TAG_Byte_Array, comparable to a collections.UserList with\n    an intrinsic name whose values must be bytes\n    \"\"\"\n    id = TAG_BYTE_ARRAY\n\n    def __init__(self, name=None, buffer=None):\n        # TODO: add a value parameter as well\n        super(TAG_Byte_Array, self).__init__(name=name)\n        if buffer:\n            self._parse_buffer(buffer)\n\n    # Parsers and Generators\n    def _parse_buffer(self, buffer):\n        length = TAG_Int(buffer=buffer)\n        self.value = bytearray(buffer.read(length.value))\n\n    def _render_buffer(self, buffer):\n        length = TAG_Int(len(self.value))\n        length._render_buffer(buffer)\n        buffer.write(bytes(self.value))\n\n    # Mixin methods\n    def __len__(self):\n        return len(self.value)\n\n    def __iter__(self):\n        return iter(self.value)\n\n    def __contains__(self, item):\n        return item in self.value\n\n    def __getitem__(self, key):\n        return self.value[key]\n\n    def __setitem__(self, key, value):\n        # TODO: check type of value\n        self.value[key] = value\n\n    def __delitem__(self, key):\n        del (self.value[key])\n\n    def insert(self, key, value):\n        # TODO: check type of value, or is this done by self.value already?\n        self.value.insert(key, value)\n\n    # Printing and Formatting of tree\n    def valuestr(self):\n        return \"[%i byte(s)]\" % len(self.value)\n\n    def __unicode__(self):\n        return '[' + \",\".join([unicode(x) for x in self.value]) + ']'\n\n    def __str__(self):\n        return '[' + \",\".join([str(x) for x in self.value]) + ']'\n\n\nclass TAG_Int_Array(TAG, MutableSequence):\n    \"\"\"\n    TAG_Int_Array, comparable to a collections.UserList with\n    an intrinsic name whose values must be integers\n    \"\"\"\n    id = TAG_INT_ARRAY\n\n    def __init__(self, name=None, buffer=None):\n        # TODO: add a value parameter as well\n        super(TAG_Int_Array, self).__init__(name=name)\n        if buffer:\n            self._parse_buffer(buffer)\n\n    def update_fmt(self, length):\n        \"\"\" Adjust struct format description to length given \"\"\"\n        self.fmt = Struct(\">\" + str(length) + \"i\")\n\n    # Parsers and Generators\n    def _parse_buffer(self, buffer):\n        length = TAG_Int(buffer=buffer).value\n        self.update_fmt(length)\n        self.value = list(self.fmt.unpack(buffer.read(self.fmt.size)))\n\n    def _render_buffer(self, buffer):\n        length = len(self.value)\n        self.update_fmt(length)\n        TAG_Int(length)._render_buffer(buffer)\n        buffer.write(self.fmt.pack(*self.value))\n\n    # Mixin methods\n    def __len__(self):\n        return len(self.value)\n\n    def __iter__(self):\n        return iter(self.value)\n\n    def __contains__(self, item):\n        return item in self.value\n\n    def __getitem__(self, key):\n        return self.value[key]\n\n    def __setitem__(self, key, value):\n        self.value[key] = value\n\n    def __delitem__(self, key):\n        del (self.value[key])\n\n    def insert(self, key, value):\n        self.value.insert(key, value)\n\n    # Printing and Formatting of tree\n    def valuestr(self):\n        return \"[%i int(s)]\" % len(self.value)\n\n\nclass TAG_Long_Array(TAG, MutableSequence):\n    \"\"\"\n    TAG_Long_Array, comparable to a collections.UserList with\n    an intrinsic name whose values must be integers\n    \"\"\"\n    id = TAG_LONG_ARRAY\n\n    def __init__(self, name=None, buffer=None):\n        super(TAG_Long_Array, self).__init__(name=name)\n        if buffer:\n            self._parse_buffer(buffer)\n\n    def update_fmt(self, length):\n        \"\"\" Adjust struct format description to length given \"\"\"\n        self.fmt = Struct(\">\" + str(length) + \"q\")\n\n    # Parsers and Generators\n    def _parse_buffer(self, buffer):\n        length = TAG_Int(buffer=buffer).value\n        self.update_fmt(length)\n        self.value = list(self.fmt.unpack(buffer.read(self.fmt.size)))\n\n    def _render_buffer(self, buffer):\n        length = len(self.value)\n        self.update_fmt(length)\n        TAG_Int(length)._render_buffer(buffer)\n        buffer.write(self.fmt.pack(*self.value))\n\n    # Mixin methods\n    def __len__(self):\n        return len(self.value)\n\n    def __iter__(self):\n        return iter(self.value)\n\n    def __contains__(self, item):\n        return item in self.value\n\n    def __getitem__(self, key):\n        return self.value[key]\n\n    def __setitem__(self, key, value):\n        self.value[key] = value\n\n    def __delitem__(self, key):\n        del (self.value[key])\n\n    def insert(self, key, value):\n        self.value.insert(key, value)\n\n    # Printing and Formatting of tree\n    def valuestr(self):\n        return \"[%i long(s)]\" % len(self.value)\n\n\nclass TAG_String(TAG, Sequence):\n    \"\"\"\n    TAG_String, comparable to a collections.UserString with an\n    intrinsic name\n    \"\"\"\n    id = TAG_STRING\n\n    def __init__(self, value=None, name=None, buffer=None):\n        super(TAG_String, self).__init__(value, name)\n        if buffer:\n            self._parse_buffer(buffer)\n\n    # Parsers and Generators\n    def _parse_buffer(self, buffer):\n        length = TAG_Short(buffer=buffer)\n        read = buffer.read(length.value)\n        if len(read) != length.value:\n            raise StructError()\n        self.value = read.decode(\"utf-8\")\n\n    def _render_buffer(self, buffer):\n        save_val = self.value.encode(\"utf-8\")\n        length = TAG_Short(len(save_val))\n        length._render_buffer(buffer)\n        buffer.write(save_val)\n\n    # Mixin methods\n    def __len__(self):\n        return len(self.value)\n\n    def __iter__(self):\n        return iter(self.value)\n\n    def __contains__(self, item):\n        return item in self.value\n\n    def __getitem__(self, key):\n        return self.value[key]\n\n    # Printing and Formatting of tree\n    def __repr__(self):\n        return self.value\n\n\n# == Collection Tags ==#\nclass TAG_List(TAG, MutableSequence):\n    \"\"\"\n    TAG_List, comparable to a collections.UserList with an intrinsic name\n    \"\"\"\n    id = TAG_LIST\n\n    def __init__(self, type=None, value=None, name=None, buffer=None):\n        super(TAG_List, self).__init__(value, name)\n        if type:\n            self.tagID = type.id\n        else:\n            self.tagID = None\n        self.tags = []\n        if buffer:\n            self._parse_buffer(buffer)\n        # if self.tagID == None:\n        #     raise ValueError(\"No type specified for list: %s\" % (name))\n\n    # Parsers and Generators\n    def _parse_buffer(self, buffer):\n        self.tagID = TAG_Byte(buffer=buffer).value\n        self.tags = []\n        length = TAG_Int(buffer=buffer)\n        for x in range(length.value):\n            self.tags.append(TAGLIST[self.tagID](buffer=buffer))\n\n    def _render_buffer(self, buffer):\n        TAG_Byte(self.tagID)._render_buffer(buffer)\n        length = TAG_Int(len(self.tags))\n        length._render_buffer(buffer)\n        for i, tag in enumerate(self.tags):\n            if tag.id != self.tagID:\n                raise ValueError(\n                    \"List element %d(%s) has type %d != container type %d\" %\n                    (i, tag, tag.id, self.tagID))\n            tag._render_buffer(buffer)\n\n    # Mixin methods\n    def __len__(self):\n        return len(self.tags)\n\n    def __iter__(self):\n        return iter(self.tags)\n\n    def __contains__(self, item):\n        return item in self.tags\n\n    def __getitem__(self, key):\n        return self.tags[key]\n\n    def __setitem__(self, key, value):\n        self.tags[key] = value\n\n    def __delitem__(self, key):\n        del (self.tags[key])\n\n    def insert(self, key, value):\n        self.tags.insert(key, value)\n\n    # Printing and Formatting of tree\n    def __repr__(self):\n        return \"%i entries of type %s\" % (\n            len(self.tags), TAGLIST[self.tagID].__name__)\n\n    # Printing and Formatting of tree\n    def valuestr(self):\n        return \"[%i %s(s)]\" % (len(self.tags), TAGLIST[self.tagID].__name__)\n\n    def __unicode__(self):\n        return \"[\" + \", \".join([tag.tag_info() for tag in self.tags]) + \"]\"\n\n    def __str__(self):\n        return \"[\" + \", \".join([tag.tag_info() for tag in self.tags]) + \"]\"\n\n    def pretty_tree(self, indent=0):\n        output = [super(TAG_List, self).pretty_tree(indent)]\n        if len(self.tags):\n            output.append((\"\\t\" * indent) + \"{\")\n            output.extend([tag.pretty_tree(indent + 1) for tag in self.tags])\n            output.append((\"\\t\" * indent) + \"}\")\n        return '\\n'.join(output)\n\n\nclass TAG_Compound(TAG, MutableMapping):\n    \"\"\"\n    TAG_Compound, comparable to a collections.OrderedDict with an\n    intrinsic name\n    \"\"\"\n    id = TAG_COMPOUND\n\n    def __init__(self, buffer=None, name=None):\n        # TODO: add a value parameter as well\n        super(TAG_Compound, self).__init__()\n        self.tags = []\n        self.name = \"\"\n        if buffer:\n            self._parse_buffer(buffer)\n\n    # Parsers and Generators\n    def _parse_buffer(self, buffer):\n        while True:\n            type = TAG_Byte(buffer=buffer)\n            if type.value == TAG_END:\n                # print(\"found tag_end\")\n                break\n            else:\n                name = TAG_String(buffer=buffer).value\n                try:\n                    tag = TAGLIST[type.value]()\n                except KeyError:\n                    raise ValueError(\"Unrecognised tag type %d\" % type.value)\n                tag.name = name\n                self.tags.append(tag)\n                tag._parse_buffer(buffer)\n\n    def _render_buffer(self, buffer):\n        for tag in self.tags:\n            TAG_Byte(tag.id)._render_buffer(buffer)\n            TAG_String(tag.name)._render_buffer(buffer)\n            tag._render_buffer(buffer)\n        buffer.write(b'\\x00')  # write TAG_END\n\n    # Mixin methods\n    def __len__(self):\n        return len(self.tags)\n\n    def __iter__(self):\n        for key in self.tags:\n            yield key.name\n\n    def __contains__(self, key):\n        if isinstance(key, int):\n            return key <= len(self.tags)\n        elif isinstance(key, basestring):\n            for tag in self.tags:\n                if tag.name == key:\n                    return True\n            return False\n        elif isinstance(key, TAG):\n            return key in self.tags\n        return False\n\n    def __getitem__(self, key):\n        if isinstance(key, int):\n            return self.tags[key]\n        elif isinstance(key, basestring):\n            for tag in self.tags:\n                if tag.name == key:\n                    return tag\n            else:\n                raise KeyError(\"Tag %s does not exist\" % key)\n        else:\n            raise TypeError(\n                \"key needs to be either name of tag, or index of tag, \"\n                \"not a %s\" % type(key).__name__)\n\n    def __setitem__(self, key, value):\n        assert isinstance(value, TAG), \"value must be an nbt.TAG\"\n        if isinstance(key, int):\n            # Just try it. The proper error will be raised if it doesn't work.\n            self.tags[key] = value\n        elif isinstance(key, basestring):\n            value.name = key\n            for i, tag in enumerate(self.tags):\n                if tag.name == key:\n                    self.tags[i] = value\n                    return\n            self.tags.append(value)\n\n    def __delitem__(self, key):\n        if isinstance(key, int):\n            del (self.tags[key])\n        elif isinstance(key, basestring):\n            self.tags.remove(self.__getitem__(key))\n        else:\n            raise ValueError(\n                \"key needs to be either name of tag, or index of tag\")\n\n    def keys(self):\n        return [tag.name for tag in self.tags]\n\n    def iteritems(self):\n        for tag in self.tags:\n            yield (tag.name, tag)\n\n    # Printing and Formatting of tree\n    def __unicode__(self):\n        return \"{\" + \", \".join([tag.tag_info() for tag in self.tags]) + \"}\"\n\n    def __str__(self):\n        return \"{\" + \", \".join([tag.tag_info() for tag in self.tags]) + \"}\"\n\n    def valuestr(self):\n        return '{%i Entries}' % len(self.tags)\n\n    def pretty_tree(self, indent=0):\n        output = [super(TAG_Compound, self).pretty_tree(indent)]\n        if len(self.tags):\n            output.append((\"\\t\" * indent) + \"{\")\n            output.extend([tag.pretty_tree(indent + 1) for tag in self.tags])\n            output.append((\"\\t\" * indent) + \"}\")\n        return '\\n'.join(output)\n\n\nTAGLIST = {TAG_END: _TAG_End, TAG_BYTE: TAG_Byte, TAG_SHORT: TAG_Short,\n           TAG_INT: TAG_Int, TAG_LONG: TAG_Long, TAG_FLOAT: TAG_Float,\n           TAG_DOUBLE: TAG_Double, TAG_BYTE_ARRAY: TAG_Byte_Array,\n           TAG_STRING: TAG_String, TAG_LIST: TAG_List,\n           TAG_COMPOUND: TAG_Compound, TAG_INT_ARRAY: TAG_Int_Array,\n           TAG_LONG_ARRAY: TAG_Long_Array}\n\n\nclass NBTFile(TAG_Compound):\n    \"\"\"Represent an NBT file object.\"\"\"\n\n    def __init__(self, filename=None, buffer=None, fileobj=None):\n        \"\"\"\n        Create a new NBTFile object.\n        Specify either a filename, file object or data buffer.\n        If filename of file object is specified, data should be GZip-compressed.\n        If a data buffer is specified, it is assumed to be uncompressed.\n        If filename is specified, the file is closed after reading and writing.\n        If file object is specified, the caller is responsible for closing the\n        file.\n        \"\"\"\n        super(NBTFile, self).__init__()\n        self.filename = filename\n        self.type = TAG_Byte(self.id)\n        closefile = True\n        # make a file object\n        if filename:\n            self.filename = filename\n            self.file = GzipFile(filename, 'rb')\n        elif buffer:\n            if hasattr(buffer, 'name'):\n                self.filename = buffer.name\n            self.file = buffer\n            closefile = False\n        elif fileobj:\n            if hasattr(fileobj, 'name'):\n                self.filename = fileobj.name\n            self.file = GzipFile(fileobj=fileobj)\n        else:\n            self.file = None\n            closefile = False\n        # parse the file given initially\n        if self.file:\n            self.parse_file()\n            if closefile:\n                # Note: GzipFile().close() does NOT close the fileobj,\n                # So we are still responsible for closing that.\n                try:\n                    self.file.close()\n                except (AttributeError, IOError):\n                    pass\n            self.file = None\n\n    def parse_file(self, filename=None, buffer=None, fileobj=None):\n        \"\"\"Completely parse a file, extracting all tags.\"\"\"\n        if filename:\n            self.file = GzipFile(filename, 'rb')\n        elif buffer:\n            if hasattr(buffer, 'name'):\n                self.filename = buffer.name\n            self.file = buffer\n        elif fileobj:\n            if hasattr(fileobj, 'name'):\n                self.filename = fileobj.name\n            self.file = GzipFile(fileobj=fileobj)\n        if self.file:\n            try:\n                type = TAG_Byte(buffer=self.file)\n                if type.value == self.id:\n                    name = TAG_String(buffer=self.file).value\n                    self._parse_buffer(self.file)\n                    self.name = name\n                    self.file.close()\n                else:\n                    raise MalformedFileError(\n                        \"First record is not a Compound Tag\")\n            except StructError as e:\n                raise MalformedFileError(\n                    \"Partial File Parse: file possibly truncated.\")\n        else:\n            raise ValueError(\n                \"NBTFile.parse_file(): Need to specify either a \"\n                \"filename or a file object\"\n            )\n\n    def write_file(self, filename=None, buffer=None, fileobj=None):\n        \"\"\"Write this NBT file to a file.\"\"\"\n        closefile = True\n        if buffer:\n            self.filename = None\n            self.file = buffer\n            closefile = False\n        elif filename:\n            self.filename = filename\n            self.file = GzipFile(filename, \"wb\")\n        elif fileobj:\n            self.filename = None\n            self.file = GzipFile(fileobj=fileobj, mode=\"wb\")\n        elif self.filename:\n            self.file = GzipFile(self.filename, \"wb\")\n        elif not self.file:\n            raise ValueError(\n                \"NBTFile.write_file(): Need to specify either a \"\n                \"filename or a file object\"\n            )\n        # Render tree to file\n        TAG_Byte(self.id)._render_buffer(self.file)\n        TAG_String(self.name)._render_buffer(self.file)\n        self._render_buffer(self.file)\n        # make sure the file is complete\n        try:\n            self.file.flush()\n        except (AttributeError, IOError):\n            pass\n        if closefile:\n            try:\n                self.file.close()\n            except (AttributeError, IOError):\n                pass\n\n    def __repr__(self):\n        \"\"\"\n        Return a string (ascii formated for Python 2, unicode\n        for Python 3) describing the class, name and id for\n        debugging purposes.\n        \"\"\"\n        if self.filename:\n            return \"<%s(%r) with %s(%r) at 0x%x>\" % (\n                self.__class__.__name__, self.filename,\n                TAG_Compound.__name__, self.name, id(self)\n            )\n        else:\n            return \"<%s with %s(%r) at 0x%x>\" % (\n                self.__class__.__name__, TAG_Compound.__name__,\n                self.name, id(self)\n            )\n复制代码\n\n\nnbt/region.py\n\n\n\n\"\"\"\nHandle a region file, containing 32x32 chunks.\nFor more information about the region file format:\nhttps://minecraft.gamepedia.com/Region_file_format\n\"\"\"\n\nfrom .nbt import NBTFile, MalformedFileError\nfrom struct import pack, unpack\nfrom collections import Mapping\nimport zlib\nimport gzip\nfrom io import BytesIO\nimport time\nfrom os import SEEK_END\n\n# constants\n\nSECTOR_LENGTH = 4096\n\"\"\"Constant indicating the length of a sector. A Region file is divided in sectors of 4096 bytes each.\"\"\"\n\n# TODO: move status codes to an (Enum) object\n\n# Status is a number representing:\n# -5 = Error, the chunk is overlapping with another chunk\n# -4 = Error, the chunk length is too large to fit in the sector length in the region header\n# -3 = Error, chunk header has a 0 length\n# -2 = Error, chunk inside the header of the region file\n# -1 = Error, chunk partially/completely outside of file\n#  0 = Ok\n#  1 = Chunk non-existant yet\nSTATUS_CHUNK_OVERLAPPING = -5\n\"\"\"Constant indicating an error status: the chunk is allocated to a sector already occupied by another chunk\"\"\"\nSTATUS_CHUNK_MISMATCHED_LENGTHS = -4\n\"\"\"Constant indicating an error status: the region header length and the chunk length are incompatible\"\"\"\nSTATUS_CHUNK_ZERO_LENGTH = -3\n\"\"\"Constant indicating an error status: chunk header has a 0 length\"\"\"\nSTATUS_CHUNK_IN_HEADER = -2\n\"\"\"Constant indicating an error status: chunk inside the header of the region file\"\"\"\nSTATUS_CHUNK_OUT_OF_FILE = -1\n\"\"\"Constant indicating an error status: chunk partially/completely outside of file\"\"\"\nSTATUS_CHUNK_OK = 0\n\"\"\"Constant indicating an normal status: the chunk exists and the metadata is valid\"\"\"\nSTATUS_CHUNK_NOT_CREATED = 1\n\"\"\"Constant indicating an normal status: the chunk does not exist\"\"\"\n\nCOMPRESSION_NONE = 0\n\"\"\"Constant indicating that the chunk is not compressed.\"\"\"\nCOMPRESSION_GZIP = 1\n\"\"\"Constant indicating that the chunk is GZip compressed.\"\"\"\nCOMPRESSION_ZLIB = 2\n\"\"\"Constant indicating that the chunk is zlib compressed.\"\"\"\n\n\n# TODO: reconsider these errors. where are they catched? Where would an implementation make a difference in handling the different exceptions.\n\nclass RegionFileFormatError(Exception):\n    \"\"\"Base class for all file format errors.\n    Note: InconceivedChunk is not a child class, because it is not considered a format error.\"\"\"\n    def __init__(self, msg=\"\"):\n        self.msg = msg\n    def __str__(self):\n        return self.msg\n\nclass NoRegionHeader(RegionFileFormatError):\n    \"\"\"The size of the region file is too small to contain a header.\"\"\"\n\nclass RegionHeaderError(RegionFileFormatError):\n    \"\"\"Error in the header of the region file for a given chunk.\"\"\"\n\nclass ChunkHeaderError(RegionFileFormatError):\n    \"\"\"Error in the header of a chunk, included the bytes of length and byte version.\"\"\"\n\nclass ChunkDataError(RegionFileFormatError):\n    \"\"\"Error in the data of a chunk.\"\"\"\n\nclass InconceivedChunk(LookupError):\n    \"\"\"Specified chunk has not yet been generated.\"\"\"\n    def __init__(self, msg=\"\"):\n        self.msg = msg\n\n\nclass ChunkMetadata(object):\n    \"\"\"\n    Metadata for a particular chunk found in the 8 kiByte header and 5-byte chunk header.\n    \"\"\"\n\n    def __init__(self, x, z):\n        self.x = x\n        \"\"\"x-coordinate of the chunk in the file\"\"\"\n        self.z = z\n        \"\"\"z-coordinate of the chunk in the file\"\"\"\n        self.blockstart = 0\n        \"\"\"start of the chunk block, counted in 4 kiByte sectors from the\n        start of the file. (24 bit int)\"\"\"\n        self.blocklength = 0\n        \"\"\"amount of 4 kiBytes sectors in the block (8 bit int)\"\"\"\n        self.timestamp = 0\n        \"\"\"a Unix timestamps (seconds since epoch) (32 bits), found in the\n        second sector in the file.\"\"\"\n        self.length = 0\n        \"\"\"length of the block in bytes. This excludes the 4-byte length header,\n        and includes the 1-byte compression byte. (32 bit int)\"\"\"\n        self.compression = None\n        \"\"\"type of compression used for the chunk block. (8 bit int).\n    \n        - 0: uncompressed\n        - 1: gzip compression\n        - 2: zlib compression\"\"\"\n        self.status = STATUS_CHUNK_NOT_CREATED\n        \"\"\"status as determined from blockstart, blocklength, length, file size\n        and location of other chunks in the file.\n        \n        - STATUS_CHUNK_OVERLAPPING\n        - STATUS_CHUNK_MISMATCHED_LENGTHS\n        - STATUS_CHUNK_ZERO_LENGTH\n        - STATUS_CHUNK_IN_HEADER\n        - STATUS_CHUNK_OUT_OF_FILE\n        - STATUS_CHUNK_OK\n        - STATUS_CHUNK_NOT_CREATED\"\"\"\n    def __str__(self):\n        return \"%s(%d, %d, sector=%s, blocklength=%s, timestamp=%s, bytelength=%s, compression=%s, status=%s)\" % \\\n            (self.__class__.__name__, self.x, self.z, self.blockstart, self.blocklength, self.timestamp, \\\n            self.length, self.compression, self.status)\n    def __repr__(self):\n        return \"%s(%d,%d)\" % (self.__class__.__name__, self.x, self.z)\n    def requiredblocks(self):\n        # slightly faster variant of: floor(self.length + 4) / 4096))\n        return (self.length + 3 + SECTOR_LENGTH) // SECTOR_LENGTH\n    def is_created(self):\n        \"\"\"return True if this chunk is created according to the header.\n        This includes chunks which are not readable for other reasons.\"\"\"\n        return self.blockstart != 0\n\nclass _HeaderWrapper(Mapping):\n    \"\"\"Wrapper around self.metadata to emulate the old self.header variable\"\"\"\n    def __init__(self, metadata):\n        self.metadata = metadata\n    def __getitem__(self, xz):\n        m = self.metadata[xz]\n        return (m.blockstart, m.blocklength, m.timestamp, m.status)\n    def __iter__(self):\n        return iter(self.metadata) # iterates over the keys\n    def __len__(self):\n        return len(self.metadata)\nclass _ChunkHeaderWrapper(Mapping):\n    \"\"\"Wrapper around self.metadata to emulate the old self.chunk_headers variable\"\"\"\n    def __init__(self, metadata):\n        self.metadata = metadata\n    def __getitem__(self, xz):\n        m = self.metadata[xz]\n        return (m.length if m.length > 0 else None, m.compression, m.status)\n    def __iter__(self):\n        return iter(self.metadata) # iterates over the keys\n    def __len__(self):\n        return len(self.metadata)\n\nclass Location(object):\n    def __init__(self, x=None, y=None, z=None):\n        self.x = x\n        self.y = y\n        self.z = z\n    def __str__(self):\n        return \"%s(x=%s, y=%s, z=%s)\" % (self.__class__.__name__, self.x, self.y, self.z)\n\nclass RegionFile(object):\n    \"\"\"A convenience class for extracting NBT files from the Minecraft Beta Region Format.\"\"\"\n    \n    # Redefine constants for backward compatibility.\n    STATUS_CHUNK_OVERLAPPING = STATUS_CHUNK_OVERLAPPING\n    \"\"\"Constant indicating an error status: the chunk is allocated to a sector\n    already occupied by another chunk. \n    Deprecated. Use :const:`nbt.region.STATUS_CHUNK_OVERLAPPING` instead.\"\"\"\n    STATUS_CHUNK_MISMATCHED_LENGTHS = STATUS_CHUNK_MISMATCHED_LENGTHS\n    \"\"\"Constant indicating an error status: the region header length and the chunk\n    length are incompatible. Deprecated. Use :const:`nbt.region.STATUS_CHUNK_MISMATCHED_LENGTHS` instead.\"\"\"\n    STATUS_CHUNK_ZERO_LENGTH = STATUS_CHUNK_ZERO_LENGTH\n    \"\"\"Constant indicating an error status: chunk header has a 0 length.\n    Deprecated. Use :const:`nbt.region.STATUS_CHUNK_ZERO_LENGTH` instead.\"\"\"\n    STATUS_CHUNK_IN_HEADER = STATUS_CHUNK_IN_HEADER\n    \"\"\"Constant indicating an error status: chunk inside the header of the region file.\n    Deprecated. Use :const:`nbt.region.STATUS_CHUNK_IN_HEADER` instead.\"\"\"\n    STATUS_CHUNK_OUT_OF_FILE = STATUS_CHUNK_OUT_OF_FILE\n    \"\"\"Constant indicating an error status: chunk partially/completely outside of file.\n    Deprecated. Use :const:`nbt.region.STATUS_CHUNK_OUT_OF_FILE` instead.\"\"\"\n    STATUS_CHUNK_OK = STATUS_CHUNK_OK\n    \"\"\"Constant indicating an normal status: the chunk exists and the metadata is valid.\n    Deprecated. Use :const:`nbt.region.STATUS_CHUNK_OK` instead.\"\"\"\n    STATUS_CHUNK_NOT_CREATED = STATUS_CHUNK_NOT_CREATED\n    \"\"\"Constant indicating an normal status: the chunk does not exist.\n    Deprecated. Use :const:`nbt.region.STATUS_CHUNK_NOT_CREATED` instead.\"\"\"\n    \n    def __init__(self, filename=None, fileobj=None, chunkclass = None):\n        \"\"\"\n        Read a region file by filename or file object. \n        If a fileobj is specified, it is not closed after use; it is the callers responibility to close it.\n        \"\"\"\n        self.file = None\n        self.filename = None\n        self._closefile = False\n        self.chunkclass = chunkclass\n        if filename:\n            self.filename = filename\n            self.file = open(filename, 'r+b') # open for read and write in binary mode\n            self._closefile = True\n        elif fileobj:\n            if hasattr(fileobj, 'name'):\n                self.filename = fileobj.name\n            self.file = fileobj\n        elif not self.file:\n            raise ValueError(\"RegionFile(): Need to specify either a filename or a file object\")\n\n        # Some variables\n        self.metadata = {}\n        \"\"\"\n        dict containing ChunkMetadata objects, gathered from metadata found in the\n        8 kiByte header and 5-byte chunk header.\n        \n        ``metadata[x, z]: ChunkMetadata()``\n        \"\"\"\n        self.header = _HeaderWrapper(self.metadata)\n        \"\"\"\n        dict containing the metadata found in the 8 kiByte header:\n        \n        ``header[x, z]: (offset, sectionlength, timestamp, status)``\n        \n        :offset: counts in 4 kiByte sectors, starting from the start of the file. (24 bit int)\n        :blocklength: is in 4 kiByte sectors (8 bit int)\n        :timestamp: is a Unix timestamps (seconds since epoch) (32 bits)\n        :status: can be any of:\n        \n            - STATUS_CHUNK_OVERLAPPING\n            - STATUS_CHUNK_MISMATCHED_LENGTHS\n            - STATUS_CHUNK_ZERO_LENGTH\n            - STATUS_CHUNK_IN_HEADER\n            - STATUS_CHUNK_OUT_OF_FILE\n            - STATUS_CHUNK_OK\n            - STATUS_CHUNK_NOT_CREATED\n        \n        Deprecated. Use :attr:`metadata` instead.\n        \"\"\"\n        self.chunk_headers = _ChunkHeaderWrapper(self.metadata)\n        \"\"\"\n        dict containing the metadata found in each chunk block:\n        \n        ``chunk_headers[x, z]: (length, compression, chunk_status)``\n        \n        :chunk length: in bytes, starting from the compression byte (32 bit int)\n        :compression: is 1 (Gzip) or 2 (bzip) (8 bit int)\n        :chunk_status: is equal to status in :attr:`header`.\n        \n        If the chunk is not defined, the tuple is (None, None, STATUS_CHUNK_NOT_CREATED)\n        \n        Deprecated. Use :attr:`metadata` instead.\n        \"\"\"\n\n        self.loc = Location()\n        \"\"\"Optional: x,z location of a region within a world.\"\"\"\n        \n        self._init_header()\n        self._parse_header()\n        self._parse_chunk_headers()\n\n    def get_size(self):\n        \"\"\" Returns the file size in bytes. \"\"\"\n        # seek(0,2) jumps to 0-bytes from the end of the file.\n        # Python 2.6 support: seek does not yet return the position.\n        self.file.seek(0, SEEK_END)\n        return self.file.tell()\n\n    @staticmethod\n    def _bytes_to_sector(bsize, sectorlength=SECTOR_LENGTH):\n        \"\"\"Given a size in bytes, return how many sections of length sectorlen are required to contain it.\n        This is equivalent to ceil(bsize/sectorlen), if Python would use floating\n        points for division, and integers for ceil(), rather than the other way around.\"\"\"\n        sectors, remainder = divmod(bsize, sectorlength)\n        return sectors if remainder == 0 else sectors + 1\n    \n    def close(self):\n        \"\"\"\n        Clean up resources after use.\n        \n        Note that the instance is no longer readable nor writable after calling close().\n        The method is automatically called by garbage collectors, but made public to\n        allow explicit cleanup.\n        \"\"\"\n        if self._closefile:\n            try:\n                self.file.close()\n            except IOError:\n                pass\n\n    def __del__(self):\n        self.close()\n        # Parent object() has no __del__ method, otherwise it should be called here.\n\n    def _init_file(self):\n        \"\"\"Initialise the file header. This will erase any data previously in the file.\"\"\"\n        header_length = 2*SECTOR_LENGTH\n        if self.size > header_length:\n            self.file.truncate(header_length)\n        self.file.seek(0)\n        self.file.write(header_length*b'\\x00')\n        self.size = header_length\n\n    def _init_header(self):\n        for x in range(32):\n            for z in range(32):\n                self.metadata[x,z] = ChunkMetadata(x, z)\n\n    def _parse_header(self):\n        \"\"\"Read the region header and stores: offset, length and status.\"\"\"\n        # update the file size, needed when parse_header is called after\n        # we have unlinked a chunk or writed a new one\n        self.size = self.get_size()\n\n        if self.size == 0:\n            # Some region files seems to have 0 bytes of size, and\n            # Minecraft handle them without problems. Take them\n            # as empty region files.\n            return\n        elif self.size < 2*SECTOR_LENGTH:\n            raise NoRegionHeader('The region file is %d bytes, too small in size to have a header.' % self.size)\n        \n        for index in range(0, SECTOR_LENGTH, 4):\n            x = int(index//4) % 32\n            z = int(index//4)//32\n            m = self.metadata[x, z]\n            \n            self.file.seek(index)\n            offset, length = unpack(\">IB\", b\"\\0\" + self.file.read(4))\n            m.blockstart, m.blocklength = offset, length\n            self.file.seek(index + SECTOR_LENGTH)\n            m.timestamp = unpack(\">I\", self.file.read(4))[0]\n            \n            if offset == 0 and length == 0:\n                m.status = STATUS_CHUNK_NOT_CREATED\n            elif length == 0:\n                m.status = STATUS_CHUNK_ZERO_LENGTH\n            elif offset < 2 and offset != 0:\n                m.status = STATUS_CHUNK_IN_HEADER\n            elif SECTOR_LENGTH * offset + 5 > self.size:\n                # Chunk header can't be read.\n                m.status = STATUS_CHUNK_OUT_OF_FILE\n            else:\n                m.status = STATUS_CHUNK_OK\n        \n        # Check for chunks overlapping in the file\n        for chunks in self._sectors()[2:]:\n            if len(chunks) > 1:\n                # overlapping chunks\n                for m in chunks:\n                    # Update status, unless these more severe errors take precedence\n                    if m.status not in (STATUS_CHUNK_ZERO_LENGTH, STATUS_CHUNK_IN_HEADER, \n                                        STATUS_CHUNK_OUT_OF_FILE):\n                        m.status = STATUS_CHUNK_OVERLAPPING\n\n    def _parse_chunk_headers(self):\n        for x in range(32):\n            for z in range(32):\n                m = self.metadata[x, z]\n                if m.status not in (STATUS_CHUNK_OK, STATUS_CHUNK_OVERLAPPING, \\\n                                    STATUS_CHUNK_MISMATCHED_LENGTHS):\n                    # skip to next if status is NOT_CREATED, OUT_OF_FILE, IN_HEADER,\n                    # ZERO_LENGTH or anything else.\n                    continue\n                try:\n                    self.file.seek(m.blockstart*SECTOR_LENGTH) # offset comes in sectors of 4096 bytes\n                    length = unpack(\">I\", self.file.read(4))\n                    m.length = length[0] # unpack always returns a tuple, even unpacking one element\n                    compression = unpack(\">B\",self.file.read(1))\n                    m.compression = compression[0]\n                except IOError:\n                    m.status = STATUS_CHUNK_OUT_OF_FILE\n                    continue\n                if m.blockstart*SECTOR_LENGTH + m.length + 4 > self.size:\n                    m.status = STATUS_CHUNK_OUT_OF_FILE\n                elif m.length <= 1: # chunk can't be zero length\n                    m.status = STATUS_CHUNK_ZERO_LENGTH\n                elif m.length + 4 > m.blocklength * SECTOR_LENGTH:\n                    # There are not enough sectors allocated for the whole block\n                    m.status = STATUS_CHUNK_MISMATCHED_LENGTHS\n\n    def _sectors(self, ignore_chunk=None):\n        \"\"\"\n        Return a list of all sectors, each sector is a list of chunks occupying the block.\n        \"\"\"\n        sectorsize = self._bytes_to_sector(self.size)\n        sectors = [[] for s in range(sectorsize)]\n        sectors[0] = True # locations\n        sectors[1] = True # timestamps\n        for m in self.metadata.values():\n            if not m.is_created():\n                continue\n            if ignore_chunk == m:\n                continue\n            if m.blocklength and m.blockstart:\n                blockend = m.blockstart + max(m.blocklength, m.requiredblocks())\n                # Ensure 2 <= b < sectorsize, as well as m.blockstart <= b < blockend\n                for b in range(max(m.blockstart, 2), min(blockend, sectorsize)):\n                    sectors[b].append(m)\n        return sectors\n\n    def _locate_free_sectors(self, ignore_chunk=None):\n        \"\"\"Return a list of booleans, indicating the free sectors.\"\"\"\n        sectors = self._sectors(ignore_chunk=ignore_chunk)\n        # Sectors are considered free, if the value is an empty list.\n        return [not i for i in sectors]\n\n    def _find_free_location(self, free_locations, required_sectors=1, preferred=None):\n        \"\"\"\n        Given a list of booleans, find a list of <required_sectors> consecutive True values.\n        If no such list is found, return length(free_locations).\n        Assumes first two values are always False.\n        \"\"\"\n        # check preferred (current) location\n        if preferred and all(free_locations[preferred:preferred+required_sectors]):\n            return preferred\n        \n        # check other locations\n        # Note: the slicing may exceed the free_location boundary.\n        # This implementation relies on the fact that slicing will work anyway,\n        # and the any() function returns True for an empty list. This ensures\n        # that blocks outside the file are considered Free as well.\n        \n        i = 2 # First two sectors are in use by the header\n        while i < len(free_locations):\n            if all(free_locations[i:i+required_sectors]):\n                break\n            i += 1\n        return i\n\n    def get_metadata(self):\n        \"\"\"\n        Return a list of the metadata of each chunk that is defined in te regionfile.\n        This includes chunks which may not be readable for whatever reason,\n        but excludes chunks that are not yet defined.\n        \"\"\"\n        return [m for m in self.metadata.values() if m.is_created()]\n\n    def get_chunks(self):\n        \"\"\"\n        Return the x,z coordinates and length of the chunks that are defined in te regionfile.\n        This includes chunks which may not be readable for whatever reason.\n        Warning: despite the name, this function does not actually return the chunk,\n        but merely it's metadata. Use get_chunk(x,z) to get the NBTFile, and then Chunk()\n        to get the actual chunk.\n        \n        This method is deprecated. Use :meth:`get_metadata` instead.\n        \"\"\"\n        return self.get_chunk_coords()\n\n    def get_chunk_coords(self):\n        \"\"\"\n        Return the x,z coordinates and length of the chunks that are defined in te regionfile.\n        This includes chunks which may not be readable for whatever reason.\n        \n        This method is deprecated. Use :meth:`get_metadata` instead.\n        \"\"\"\n        chunks = []\n        for x in range(32):\n            for z in range(32):\n                m = self.metadata[x,z]\n                if m.is_created():\n                    chunks.append({'x': x, 'z': z, 'length': m.blocklength})\n        return chunks\n\n    def iter_chunks(self):\n        \"\"\"\n        Yield each readable chunk present in the region.\n        Chunks that can not be read for whatever reason are silently skipped.\n        Warning: this function returns a :class:`nbt.nbt.NBTFile` object, use ``Chunk(nbtfile)`` to get a\n        :class:`nbt.chunk.Chunk` instance.\n        \"\"\"\n        for m in self.get_metadata():\n            try:\n                yield self.get_chunk(m.x, m.z)\n            except RegionFileFormatError:\n                pass\n\n    # The following method will replace 'iter_chunks'\n    # but the previous is kept for the moment\n    # until the users update their code\n\n    def iter_chunks_class(self):\n        \"\"\"\n        Yield each readable chunk present in the region.\n        Chunks that can not be read for whatever reason are silently skipped.\n        This function returns a :class:`nbt.chunk.Chunk` instance.\n        \"\"\"\n        for m in self.get_metadata():\n            try:\n                yield self.chunkclass(self.get_chunk(m.x, m.z))\n            except RegionFileFormatError:\n                pass\n\n    def __iter__(self):\n        return self.iter_chunks()\n\n    def get_timestamp(self, x, z):\n        \"\"\"\n        Return the timestamp of when this region file was last modified.\n        \n        Note that this returns the timestamp as-is. A timestamp may exist, \n        while the chunk does not, or it may return a timestamp of 0 even \n        while the chunk exists.\n        \n        To convert to an actual date, use `datetime.fromtimestamp()`.\n        \"\"\"\n        return self.metadata[x,z].timestamp\n\n    def chunk_count(self):\n        \"\"\"Return the number of defined chunks. This includes potentially corrupt chunks.\"\"\"\n        return len(self.get_metadata())\n\n    def get_blockdata(self, x, z):\n        \"\"\"\n        Return the decompressed binary data representing a chunk.\n        \n        May raise a RegionFileFormatError().\n        If decompression of the data succeeds, all available data is returned, \n        even if it is shorter than what is specified in the header (e.g. in case\n        of a truncated while and non-compressed data).\n        \"\"\"\n        # read metadata block\n        m = self.metadata[x, z]\n        if m.status == STATUS_CHUNK_NOT_CREATED:\n            raise InconceivedChunk(\"Chunk %d,%d is not present in region\" % (x,z))\n        elif m.status == STATUS_CHUNK_IN_HEADER:\n            raise RegionHeaderError('Chunk %d,%d is in the region header' % (x,z))\n        elif m.status == STATUS_CHUNK_OUT_OF_FILE and (m.length <= 1 or m.compression == None):\n            # Chunk header is outside of the file.\n            raise RegionHeaderError('Chunk %d,%d is partially/completely outside the file' % (x,z))\n        elif m.status == STATUS_CHUNK_ZERO_LENGTH:\n            if m.blocklength == 0:\n                raise RegionHeaderError('Chunk %d,%d has zero length' % (x,z))\n            else:\n                raise ChunkHeaderError('Chunk %d,%d has zero length' % (x,z))\n        elif m.blockstart * SECTOR_LENGTH + 5 >= self.size:\n            raise RegionHeaderError('Chunk %d,%d is partially/completely outside the file' % (x,z))\n\n        # status is STATUS_CHUNK_OK, STATUS_CHUNK_MISMATCHED_LENGTHS, STATUS_CHUNK_OVERLAPPING\n        # or STATUS_CHUNK_OUT_OF_FILE.\n        # The chunk is always read, but in case of an error, the exception may be different \n        # based on the status.\n\n        err = None\n        try:\n            # offset comes in sectors of 4096 bytes + length bytes + compression byte\n            self.file.seek(m.blockstart * SECTOR_LENGTH + 5)\n            # Do not read past the length of the file.\n            # The length in the file includes the compression byte, hence the -1.\n            length = min(m.length - 1, self.size - (m.blockstart * SECTOR_LENGTH + 5))\n            chunk = self.file.read(length)\n            \n            if (m.compression == COMPRESSION_GZIP):\n                # Python 3.1 and earlier do not yet support gzip.decompress(chunk)\n                f = gzip.GzipFile(fileobj=BytesIO(chunk))\n                chunk = bytes(f.read())\n                f.close()\n            elif (m.compression == COMPRESSION_ZLIB):\n                chunk = zlib.decompress(chunk)\n            elif m.compression != COMPRESSION_NONE:\n                raise ChunkDataError('Unknown chunk compression/format (%s)' % m.compression)\n            \n            return chunk\n        except RegionFileFormatError:\n            raise\n        except Exception as e:\n            # Deliberately catch the Exception and re-raise.\n            # The details in gzip/zlib/nbt are irrelevant, just that the data is garbled.\n            err = '%s' % e # avoid str(e) due to Unicode issues in Python 2.\n        if err:\n            # don't raise during exception handling to avoid the warning \n            # \"During handling of the above exception, another exception occurred\".\n            # Python 3.3 solution (see PEP 409 & 415): \"raise ChunkDataError(str(e)) from None\"\n            if m.status == STATUS_CHUNK_MISMATCHED_LENGTHS:\n                raise ChunkHeaderError('The length in region header and the length in the header of chunk %d,%d are incompatible' % (x,z))\n            elif m.status == STATUS_CHUNK_OVERLAPPING:\n                raise ChunkHeaderError('Chunk %d,%d is overlapping with another chunk' % (x,z))\n            else:\n                raise ChunkDataError(err)\n\n    def get_nbt(self, x, z):\n        \"\"\"\n        Return a NBTFile of the specified chunk.\n        Raise InconceivedChunk if the chunk is not included in the file.\n        \"\"\"\n        # TODO: cache results?\n        data = self.get_blockdata(x, z) # This may raise a RegionFileFormatError.\n        data = BytesIO(data)\n        err = None\n        try:\n            nbt = NBTFile(buffer=data)\n            if self.loc.x != None:\n                x += self.loc.x*32\n            if self.loc.z != None:\n                z += self.loc.z*32\n            nbt.loc = Location(x=x, z=z)\n            return nbt\n            # this may raise a MalformedFileError. Convert to ChunkDataError.\n        except MalformedFileError as e:\n            err = '%s' % e # avoid str(e) due to Unicode issues in Python 2.\n        if err:\n            raise ChunkDataError(err)\n\n    def get_chunk(self, x, z):\n        \"\"\"\n        Return a NBTFile of the specified chunk.\n        Raise InconceivedChunk if the chunk is not included in the file.\n        \n        Note: this function may be changed later to return a Chunk() rather \n        than a NBTFile() object. To keep the old functionality, use get_nbt().\n        \"\"\"\n        return self.get_nbt(x, z)\n\n    def write_blockdata(self, x, z, data, compression=COMPRESSION_ZLIB):\n        \"\"\"\n        Compress the data, write it to file, and add pointers in the header so it \n        can be found as chunk(x,z).\n        \"\"\"\n        if compression == COMPRESSION_GZIP:\n            # Python 3.1 and earlier do not yet support `data = gzip.compress(data)`.\n            compressed_file = BytesIO()\n            f = gzip.GzipFile(fileobj=compressed_file)\n            f.write(data)\n            f.close()\n            compressed_file.seek(0)\n            data = compressed_file.read()\n            del compressed_file\n        elif compression == COMPRESSION_ZLIB:\n            data = zlib.compress(data) # use zlib compression, rather than Gzip\n        elif compression != COMPRESSION_NONE:\n            raise ValueError(\"Unknown compression type %d\" % compression)\n        length = len(data)\n\n        # 5 extra bytes are required for the chunk block header\n        nsectors = self._bytes_to_sector(length + 5)\n\n        if nsectors >= 256:\n            raise ChunkDataError(\"Chunk is too large (%d sectors exceeds 255 maximum)\" % (nsectors))\n\n        # Ensure file has a header\n        if self.size < 2*SECTOR_LENGTH:\n            self._init_file()\n\n        # search for a place where to write the chunk:\n        current = self.metadata[x, z]\n        free_sectors = self._locate_free_sectors(ignore_chunk=current)\n        sector = self._find_free_location(free_sectors, nsectors, preferred=current.blockstart)\n\n        # If file is smaller than sector*SECTOR_LENGTH (it was truncated), pad it with zeroes.\n        if self.size < sector*SECTOR_LENGTH:\n            # jump to end of file\n            self.file.seek(0, SEEK_END)\n            self.file.write((sector*SECTOR_LENGTH - self.size) * b\"\\x00\")\n            assert self.file.tell() == sector*SECTOR_LENGTH\n\n        # write out chunk to region\n        self.file.seek(sector*SECTOR_LENGTH)\n        self.file.write(pack(\">I\", length + 1)) #length field\n        self.file.write(pack(\">B\", compression)) #compression field\n        self.file.write(data) #compressed data\n\n        # Write zeros up to the end of the chunk\n        remaining_length = SECTOR_LENGTH * nsectors - length - 5\n        self.file.write(remaining_length * b\"\\x00\")\n\n        #seek to header record and write offset and length records\n        self.file.seek(4 * (x + 32*z))\n        self.file.write(pack(\">IB\", sector, nsectors)[1:])\n\n        #write timestamp\n        self.file.seek(SECTOR_LENGTH + 4 * (x + 32*z))\n        timestamp = int(time.time())\n        self.file.write(pack(\">I\", timestamp))\n\n        # Update free_sectors with newly written block\n        # This is required for calculating file truncation and zeroing freed blocks.\n        free_sectors.extend((sector + nsectors - len(free_sectors)) * [True])\n        for s in range(sector, sector + nsectors):\n            free_sectors[s] = False\n        \n        # Check if file should be truncated:\n        truncate_count = list(reversed(free_sectors)).index(False)\n        if truncate_count > 0:\n            self.size = SECTOR_LENGTH * (len(free_sectors) - truncate_count)\n            self.file.truncate(self.size)\n            free_sectors = free_sectors[:-truncate_count]\n        \n        # Calculate freed sectors\n        for s in range(current.blockstart, min(current.blockstart + current.blocklength, len(free_sectors))):\n            if free_sectors[s]:\n                # zero sector s\n                self.file.seek(SECTOR_LENGTH*s)\n                self.file.write(SECTOR_LENGTH*b'\\x00')\n        \n        # update file size and header information\n        self.size = max((sector + nsectors)*SECTOR_LENGTH, self.size)\n        assert self.get_size() == self.size\n        current.blockstart = sector\n        current.blocklength = nsectors\n        current.status = STATUS_CHUNK_OK\n        current.timestamp = timestamp\n        current.length = length + 1\n        current.compression = COMPRESSION_ZLIB\n\n        # self.parse_header()\n        # self.parse_chunk_headers()\n\n    def write_chunk(self, x, z, nbt_file):\n        \"\"\"\n        Pack the NBT file as binary data, and write to file in a compressed format.\n        \"\"\"\n        data = BytesIO()\n        nbt_file.write_file(buffer=data) # render to buffer; uncompressed\n        self.write_blockdata(x, z, data.getvalue())\n\n    def unlink_chunk(self, x, z):\n        \"\"\"\n        Remove a chunk from the header of the region file.\n        Fragmentation is not a problem, chunks are written to free sectors when possible.\n        \"\"\"\n        # This function fails for an empty file. If that is the case, just return.\n        if self.size < 2*SECTOR_LENGTH:\n            return\n\n        # zero the region header for the chunk (offset length and time)\n        self.file.seek(4 * (x + 32*z))\n        self.file.write(pack(\">IB\", 0, 0)[1:])\n        self.file.seek(SECTOR_LENGTH + 4 * (x + 32*z))\n        self.file.write(pack(\">I\", 0))\n\n        # Check if file should be truncated:\n        current = self.metadata[x, z]\n        free_sectors = self._locate_free_sectors(ignore_chunk=current)\n        truncate_count = list(reversed(free_sectors)).index(False)\n        if truncate_count > 0:\n            self.size = SECTOR_LENGTH * (len(free_sectors) - truncate_count)\n            self.file.truncate(self.size)\n            free_sectors = free_sectors[:-truncate_count]\n        \n        # Calculate freed sectors\n        for s in range(current.blockstart, min(current.blockstart + current.blocklength, len(free_sectors))):\n            if free_sectors[s]:\n                # zero sector s\n                self.file.seek(SECTOR_LENGTH*s)\n                self.file.write(SECTOR_LENGTH*b'\\x00')\n\n        # update the header\n        self.metadata[x, z] = ChunkMetadata(x, z)\n\n    def _classname(self):\n        \"\"\"Return the fully qualified class name.\"\"\"\n        if self.__class__.__module__ in (None,):\n            return self.__class__.__name__\n        else:\n            return \"%s.%s\" % (self.__class__.__module__, self.__class__.__name__)\n\n    def __str__(self):\n        if self.filename:\n            return \"<%s(%r)>\" % (self._classname(), self.filename)\n        else:\n            return '<%s object at %d>' % (self._classname(), id(self))\n    \n    def __repr__(self):\n        if self.filename:\n            return \"%s(%r)\" % (self._classname(), self.filename)\n        else:\n            return '<%s object at %d>' % (self._classname(), id(self))\n复制代码\n\nnbt/world.py\n\n\n\"\"\"\nHandles a Minecraft world save using either the Anvil or McRegion format.\nFor more information about the world format:\nhttps://minecraft.gamepedia.com/Level_format\n\"\"\"\n\nimport os, glob, re\nfrom . import region\nfrom . import chunk\nfrom .region import InconceivedChunk, Location\n\nclass UnknownWorldFormat(Exception):\n    \"\"\"Unknown or invalid world folder.\"\"\"\n    def __init__(self, msg=\"\"):\n        self.msg = msg\n\n\nclass _BaseWorldFolder(object):\n    \"\"\"\n    Abstract class, representing either a McRegion or Anvil world folder.\n    This class will use either Anvil or McRegion, with Anvil the preferred format.\n    Simply calling WorldFolder() will do this automatically.\n    \"\"\"\n    type = \"Generic\"\n    extension = ''\n    chunkclass = chunk.Chunk\n\n    def __init__(self, world_folder):\n        \"\"\"Initialize a WorldFolder.\"\"\"\n        self.worldfolder = world_folder\n        self.regionfiles = {}\n        self.regions     = {}\n        self.chunks  = None\n        # os.listdir triggers an OSError for non-existant directories or permission errors.\n        # This is needed, because glob.glob silently returns no files.\n        os.listdir(world_folder)\n        self.set_regionfiles(self.get_filenames())\n\n    def get_filenames(self):\n        \"\"\"Find all matching file names in the world folder.\n        \n        This method is private, and it's use it deprecated. Use get_regionfiles() instead.\"\"\"\n        # Warning: glob returns a empty list if the directory is unreadable, without raising an Exception\n        return list(glob.glob(os.path.join(self.worldfolder,'region','r.*.*.'+self.extension)))\n\n    def set_regionfiles(self, filenames):\n        \"\"\"\n        This method directly sets the region files for this instance to use.\n        It assumes the filenames are in the form r.<x-digit>.<z-digit>.<extension>\n        \"\"\"\n        for filename in filenames:\n            # Assume that filenames have the name r.<x-digit>.<z-digit>.<extension>\n            m = re.match(r\"r.(\\-?\\d+).(\\-?\\d+).\"+self.extension, os.path.basename(filename))\n            if m:\n                x = int(m.group(1))\n                z = int(m.group(2))\n            else:\n                # Only raised if a .mca of .mcr file exists which does not comply to the\n                #  r.<x-digit>.<z-digit>.<extension> filename format. This may raise false\n                # errors if a copy is made, e.g. \"r.0.-1 copy.mca\". If this is an issue, override\n                # get_filenames(). In most cases, it is an error, and we like to raise that.\n                # Changed, no longer raise error, because we want to continue the loop.\n                # raise UnknownWorldFormat(\"Unrecognized filename format %s\" % os.path.basename(filename))\n                # TODO: log to stderr using logging facility.\n                pass\n            self.regionfiles[(x,z)] = filename\n\n    def get_regionfiles(self):\n        \"\"\"Return a list of full path of all region files.\"\"\"\n        return list(self.regionfiles.values())\n\n    def nonempty(self):\n        \"\"\"Return True is the world is non-empty.\"\"\"\n        return len(self.regionfiles) > 0\n\n    def get_region(self, x,z):\n        \"\"\"Get a region using x,z coordinates of a region. Cache results.\"\"\"\n        if (x,z) not in self.regions:\n            if (x,z) in self.regionfiles:\n                self.regions[(x,z)] = region.RegionFile(self.regionfiles[(x,z)])\n            else:\n                # Return an empty RegionFile object\n                # TODO: this does not yet allow for saving of the region file\n                # TODO: this currently fails with a ValueError!\n                # TODO: generate the correct name, and create the file\n                # and add the fie to self.regionfiles\n                self.regions[(x,z)] = region.RegionFile()\n            self.regions[(x,z)].loc = Location(x=x,z=z)\n        return self.regions[(x,z)]\n\n    def iter_regions(self):\n        \"\"\"\n        Return an iterable list of all region files. Use this function if you only\n        want to loop through each region files once, and do not want to cache the results.\n        \"\"\"\n        # TODO: Implement BoundingBox\n        # TODO: Implement sort order\n        for x,z in self.regionfiles.keys():\n            close_after_use = False\n            if (x,z) in self.regions:\n                regionfile = self.regions[(x,z)]\n            else:\n                # It is not yet cached.\n                # Get file, but do not cache later.\n                regionfile = region.RegionFile(self.regionfiles[(x,z)], chunkclass = self.chunkclass)\n                regionfile.loc = Location(x=x,z=z)\n                close_after_use = True\n            try:\n                yield regionfile\n            finally:\n                if close_after_use:\n                    regionfile.close()\n\n    def call_for_each_region(self, callback_function, boundingbox=None):\n        \"\"\"\n        Return an iterable that calls callback_function for each region file \n        in the world. This is equivalent to:\n        ```\n        for the_region in iter_regions():\n                yield callback_function(the_region)\n        ````\n        \n        This function is threaded. It uses pickle to pass values between threads.\n        See [What can be pickled and unpickled?](https://docs.python.org/library/pickle.html#what-can-be-pickled-and-unpickled) in the Python documentation\n        for limitation on the output of `callback_function()`.\n        \"\"\"\n        raise NotImplementedError()\n\n    def get_nbt(self,x,z):\n        \"\"\"\n        Return a NBT specified by the chunk coordinates x,z. Raise InconceivedChunk\n        if the NBT file is not yet generated. To get a Chunk object, use get_chunk.\n        \"\"\"\n        rx,cx = divmod(x,32)\n        rz,cz = divmod(z,32)\n        if (rx,rz) not in self.regions and (rx,rz) not in self.regionfiles:\n            raise InconceivedChunk(\"Chunk %s,%s is not present in world\" % (x,z))\n        nbt = self.get_region(rx,rz).get_nbt(cx,cz)\n        assert nbt != None\n        return nbt\n\n    def set_nbt(self,x,z,nbt):\n        \"\"\"\n        Set a chunk. Overrides the NBT if it already existed. If the NBT did not exists,\n        adds it to the Regionfile. May create a new Regionfile if that did not exist yet.\n        nbt must be a nbt.NBTFile instance, not a Chunk or regular TAG_Compound object.\n        \"\"\"\n        raise NotImplementedError()\n        # TODO: implement\n\n    def iter_nbt(self):\n        \"\"\"\n        Return an iterable list of all NBT. Use this function if you only\n        want to loop through the chunks once, and don't need the block or data arrays.\n        \"\"\"\n        # TODO: Implement BoundingBox\n        # TODO: Implement sort order\n        for region in self.iter_regions():\n            for c in region.iter_chunks():\n                yield c\n\n    def call_for_each_nbt(self, callback_function, boundingbox=None):\n        \"\"\"\n        Return an iterable that calls callback_function for each NBT structure \n        in the world. This is equivalent to:\n        ```\n        for the_nbt in iter_nbt():\n                yield callback_function(the_nbt)\n        ````\n        \n        This function is threaded. It uses pickle to pass values between threads.\n        See [What can be pickled and unpickled?](https://docs.python.org/library/pickle.html#what-can-be-pickled-and-unpickled) in the Python documentation\n        for limitation on the output of `callback_function()`.\n        \"\"\"\n        raise NotImplementedError()\n\n    def get_chunk(self,x,z):\n        \"\"\"\n        Return a chunk specified by the chunk coordinates x,z. Raise InconceivedChunk\n        if the chunk is not yet generated. To get the raw NBT data, use get_nbt.\n        \"\"\"\n        return self.chunkclass(self.get_nbt(x, z))\n\n    def get_chunks(self, boundingbox=None):\n        \"\"\"\n        Return a list of all chunks. Use this function if you access the chunk\n        list frequently and want to cache the result.\n        Use iter_chunks() if you only want to loop through the chunks once or have a\n        very large world.\n        \"\"\"\n        if self.chunks == None:\n            self.chunks = list(self.iter_chunks())\n        return self.chunks\n\n    def iter_chunks(self):\n        \"\"\"\n        Return an iterable list of all chunks. Use this function if you only\n        want to loop through the chunks once or have a very large world.\n        Use get_chunks() if you access the chunk list frequently and want to cache\n        the results. Use iter_nbt() if you are concerned about speed and don't want\n        to parse the block data.\n        \"\"\"\n        # TODO: Implement BoundingBox\n        # TODO: Implement sort order\n        for c in self.iter_nbt():\n            yield self.chunkclass(c)\n\n    def chunk_count(self):\n        \"\"\"Return a count of the chunks in this world folder.\"\"\"\n        c = 0\n        for r in self.iter_regions():\n            c += r.chunk_count()\n        return c\n\n    def get_boundingbox(self):\n        \"\"\"\n        Return minimum and maximum x and z coordinates of the chunks that\n        make up this world save\n        \"\"\"\n        b = BoundingBox()\n        for rx,rz in self.regionfiles.keys():\n            region = self.get_region(rx,rz)\n            rx,rz = 32*rx,32*rz\n            for cc in region.get_chunk_coords():\n                x,z = (rx+cc['x'],rz+cc['z'])\n                b.expand(x,None,z)\n        return b\n\n    def __repr__(self):\n        return \"%s(%r)\" % (self.__class__.__name__,self.worldfolder)\n\n\nclass McRegionWorldFolder(_BaseWorldFolder):\n    \"\"\"Represents a world save using the old McRegion format.\"\"\"\n    type = \"McRegion\"\n    extension = 'mcr'\n    chunkclass = chunk.McRegionChunk\n\n\nclass AnvilWorldFolder(_BaseWorldFolder):\n    \"\"\"Represents a world save using the new Anvil format.\"\"\"\n    type = \"Anvil\"\n    extension = 'mca'\n    chunkclass = chunk.AnvilChunk\n\n\nclass _WorldFolderFactory(object):\n    \"\"\"Factory class: instantiate the subclassses in order, and the first instance \n    whose nonempty() method returns True is returned. If no nonempty() returns True,\n    a UnknownWorldFormat exception is raised.\"\"\"\n    def __init__(self, subclasses):\n        self.subclasses = subclasses\n    def __call__(self, *args, **kwargs):\n        for cls in self.subclasses:\n            wf = cls(*args, **kwargs)\n            if wf.nonempty(): # Check if the world is non-empty\n                return wf\n        raise UnknownWorldFormat(\"Empty world or unknown format\")\n\nWorldFolder = _WorldFolderFactory([AnvilWorldFolder, McRegionWorldFolder])\n\"\"\"\nFactory instance that returns a AnvilWorldFolder or McRegionWorldFolder\ninstance, or raise a UnknownWorldFormat.\n\"\"\"\n\n\n\nclass BoundingBox(object):\n    \"\"\"A bounding box of x,y,z coordinates.\"\"\"\n    def __init__(self, minx=None, maxx=None, miny=None, maxy=None, minz=None, maxz=None):\n        self.minx,self.maxx = minx, maxx\n        self.miny,self.maxy = miny, maxy\n        self.minz,self.maxz = minz, maxz\n    def expand(self,x,y,z):\n        \"\"\"\n        Expands the bounding\n        \"\"\"\n        if x != None:\n            if self.minx is None or x < self.minx:\n                self.minx = x\n            if self.maxx is None or x > self.maxx:\n                self.maxx = x\n        if y != None:\n            if self.miny is None or y < self.miny:\n                self.miny = y\n            if self.maxy is None or y > self.maxy:\n                self.maxy = y\n        if z != None:\n            if self.minz is None or z < self.minz:\n                self.minz = z\n            if self.maxz is None or z > self.maxz:\n                self.maxz = z\n    def lenx(self):\n        if self.maxx is None or self.minx is None:\n            return 0\n        return self.maxx-self.minx+1\n    def leny(self):\n        if self.maxy is None or self.miny is None:\n            return 0\n        return self.maxy-self.miny+1\n    def lenz(self):\n        if self.maxz is None or self.minz is None:\n            return 0\n        return self.maxz-self.minz+1\n    def __repr__(self):\n        return \"%s(%s,%s,%s,%s,%s,%s)\" % (self.__class__.__name__,self.minx,self.maxx,\n                self.miny,self.maxy,self.minz,self.maxz)复制代码\n\n/setup.py\n#!/usr/bin/env python\n\nfrom setuptools import setup\nfrom nbt import VERSION\n\nsetup(\n  name             = 'NBT',\n  version          = \".\".join(str(x) for x in VERSION),\n  description      = 'Named Binary Tag Reader/Writer',\n  author           = 'Thomas Woolford',\n  author_email     = 'woolford.thomas@gmail.com',\n  url              = 'http://github.com/twoolie/NBT',\n  license          = open(\"LICENSE.txt\").read(),\n  long_description = open(\"README.txt\").read(),\n  packages         = ['nbt'],\n  classifiers      = [\n        \"Development Status :: 5 - Production/Stable\",\n        \"Intended Audience :: Developers\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n        \"Programming Language :: Python\",\n        \"Programming Language :: Python :: 2.7\",\n        \"Programming Language :: Python :: 3.3\",\n        \"Programming Language :: Python :: 3.4\",\n        \"Programming Language :: Python :: 3.5\",\n        \"Programming Language :: Python :: 3.6\",\n        \"Topic :: Games/Entertainment\",\n        \"Topic :: Software Development :: Libraries :: Python Modules\"\n  ]\n)复制代码\n"
        },
        {
            "author": "阴阳师元素祭祀",
            "timestamp": 1586613120,
            "txt_content": " 本帖最后由 阴阳师元素祭祀 于 2020-4-11 21:57 编辑 \n\n有啊有啊\n一个编程语言怎么可能读写不了文件呢\n按照字节读自己解析即可了\nhttps://wiki.biligame.com/mc/NBT%E6%A0%BC%E5%BC%8F\n\n代码思路可以参考\nhttps://www.mcbbs.net/thread-1014198-272076-1.html\n这边帮忙折叠了只解析了int和{}的nbt代码\n\n  private static String getYYS(int depth) {\n        StringBuilder sb = new StringBuilder();\n        for (int i = 0; i < depth; ++i) {\n            sb.append(\"    \");\n        }\n        return sb.toString();\n    }\n    private static void read(DataInputStream in, int depth) throws IOException {\n        boolean next = true;\n        while (next) {\n            byte tag = in.readByte();\n            next = tag != 0;\n            if (next) {\n                short nameLength = in.readShort();\n                if (nameLength != 0) {\n                    byte[] name = new byte[nameLength];\n                    if (in.read(name) != name.length) {\n                        throw new IOException(\"ljyys for name error\");\n                    }\n                    String tagName = new String(name);\n                    System.out.println(getYYS(depth) + tagName + \" {\");\n                } else {\n                    System.out.println(getYYS(depth) + \"{\");\n                }\n                switch (tag) {\n                    case 0x3: {\n                        System.out.println(getYYS(depth + 1) + in.readInt());\n                        System.out.println(getYYS(depth) + \"}\");\n                        break;\n                    }\n                    case 0xA: {\n                        read(in, depth + 1);\n                        next = in.available() > 0;\n                        break;\n                    }\n                    default: {\n                        System.out.println(\"data left: \" + in.available());\n                        throw new IOException(\"ljyys for tag:\" + tag);\n                    }\n                }\n            }\n        }\n        System.out.println(getYYS(depth) + \"}\");\n    }\n    public static void main(String[] args) throws Throwable {\n        DataInputStream in = new DataInputStream(Files.newInputStream(Paths.get(\"command_storage_minecraft\")));\n        read(in, 0);\n    }复制代码\n\n\n\n我相信 简单 的 python 代码 会更少\n\n\npy:\nopen(...)\nread(...)\n我相信楼主肯定会python 不至于基础代码还需要教\n\n\n\n"
        },
        {
            "author": "(=°ω°)丿",
            "timestamp": 1586613180,
            "txt_content": "阴阳师元素祭祀 发表于 2020-4-11 21:52\n有啊有啊\n一个编程语言怎么可能读写不了文件呢\nhttps://wiki.biligame.com/mc/NBT%E6%A0%BC%E5%BC%8F\n我说的是 python 而你给的是 java（"
        },
        {
            "author": "阴阳师元素祭祀",
            "timestamp": 1586614140,
            "txt_content": " 本帖最后由 阴阳师元素祭祀 于 2020-4-11 22:15 编辑 \n(=°ω°)丿 发表于 2020-4-11 21:53\n我说的是 python 而你给的是 java（\n根据隔壁群的情况 我猜测\n你需要\n@箱子 的好东西\n\n[搬运+翻译][从零学编程]Python3Ⅳ：异常 & 文件\nhttps://www.mcbbs.net/thread-990257-1-1.html\n(出处: Minecraft(我的世界)中文论坛)\n\n你 该不会想要完整代码吧...   走莉走莉"
        },
        {
            "author": "(=°ω°)丿",
            "timestamp": 1586615040,
            "txt_content": "阴阳师元素祭祀 发表于 2020-4-11 22:09\n根据隔壁群的情况 我猜测\n你需要\n@箱子 的好东西\n那你就帮我把 https://pca006132.neocities.org/tutorials/nbt/format.html 里的 python nbt 库下载下来吧（我打不开），其他的我自己解决好了（\n\n只学一门编程语言是没有前途的（"
        }
    ]
}